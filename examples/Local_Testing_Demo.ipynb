{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üá∫üá¶ Ukrainian OCR Pipeline - Local Testing Demo\n",
    "\n",
    "High-performance OCR pipeline for historical Ukrainian documents with Named Entity Recognition (NER).\n",
    "\n",
    "**Features:**\n",
    "- ‚ö° GPU-accelerated TrOCR for Cyrillic handwriting (or CPU fallback)\n",
    "- üéØ Named Entity Recognition for persons and locations\n",
    "- üìã ALTO XML output for archival standards\n",
    "- üé® Person-dense region extraction\n",
    "- üìä Progress tracking and performance monitoring\n",
    "\n",
    "**Local Environment Requirements:**\n",
    "- Python 3.8+\n",
    "- PyTorch (CPU or GPU)\n",
    "- Ukrainian OCR package installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Setup and Installation\n",
    "\n",
    "First, let's install the Ukrainian OCR pipeline package and check system availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're in the package directory and install\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add package to Python path if we're in development mode\n",
    "if os.path.exists('../ukrainian_ocr'):\n",
    "    sys.path.insert(0, '..')\n",
    "    print(\"‚úÖ Using development version from parent directory\")\n",
    "elif os.path.exists('./ukrainian_ocr'):\n",
    "    sys.path.insert(0, '.')\n",
    "    print(\"‚úÖ Using development version from current directory\")\n",
    "else:\n",
    "    print(\"üì¶ Using installed package\")\n",
    "\n",
    "# Test import\n",
    "try:\n",
    "    import ukrainian_ocr\n",
    "    print(f\"‚úÖ Ukrainian OCR v{ukrainian_ocr.__version__} loaded successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing package: {e}\")\n",
    "    print(\"üí° Install with: pip install -e . (from package root)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check system capabilities\n",
    "import torch\n",
    "from ukrainian_ocr.utils.gpu import check_gpu_availability, optimize_for_device\n",
    "\n",
    "print(\"üîç System Information:\")\n",
    "print(f\"  Python: {sys.version.split()[0]}\")\n",
    "print(f\"  PyTorch: {torch.__version__}\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"  GPU Memory: {gpu_memory:.1f}GB\")\n",
    "    recommended_device = 'cuda'\n",
    "else:\n",
    "    print(\"  Will use CPU processing (slower but works)\")\n",
    "    recommended_device = 'cpu'\n",
    "\n",
    "print(f\"  Recommended device: {recommended_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Setup Test Images\n",
    "\n",
    "Set up test images from your local filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test image paths - modify these for your local setup\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Option 1: Use specific test images\n",
    "test_images = [\n",
    "    \"/home/maria/ssd990/projects/tarkovsky/–ù-2982_4_1001/804-03494422-l-m-a-n2982-4-1001-00001.jpg\",\n",
    "    \"/home/maria/ssd990/projects/tarkovsky/–ù-2982_4_1001/804-03494422-l-m-a-n2982-4-1001-00002.jpg\"\n",
    "]\n",
    "\n",
    "# Option 2: Auto-discover images in a directory\n",
    "test_dir = \"/home/maria/ssd990/projects/tarkovsky/–ù-2982_4_1001/\"\n",
    "if os.path.exists(test_dir):\n",
    "    discovered_images = glob.glob(os.path.join(test_dir, \"*.jpg\")) + \\\n",
    "                       glob.glob(os.path.join(test_dir, \"*.png\"))\n",
    "    print(f\"üìÅ Found {len(discovered_images)} images in {test_dir}\")\n",
    "    \n",
    "    # Use first few for testing\n",
    "    if discovered_images:\n",
    "        test_images = discovered_images[:3]  # Limit to first 3 for testing\n",
    "\n",
    "# Option 3: Manually specify your test images\n",
    "# Uncomment and modify these paths:\n",
    "# test_images = [\n",
    "#     \"/path/to/your/test/image1.jpg\",\n",
    "#     \"/path/to/your/test/image2.jpg\"\n",
    "# ]\n",
    "\n",
    "# Filter existing images\n",
    "existing_images = [img for img in test_images if os.path.exists(img)]\n",
    "\n",
    "print(f\"\\nüìä Test Images Setup:\")\n",
    "print(f\"  Total specified: {len(test_images)}\")\n",
    "print(f\"  Existing files: {len(existing_images)}\")\n",
    "\n",
    "if existing_images:\n",
    "    print(\"\\nüìÑ Images to process:\")\n",
    "    for i, img in enumerate(existing_images, 1):\n",
    "        size_mb = os.path.getsize(img) / 1024 / 1024\n",
    "        print(f\"  {i}. {os.path.basename(img)} ({size_mb:.1f}MB)\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No test images found!\")\n",
    "    print(\"üí° Please update the test_images list with valid image paths\")\n",
    "\n",
    "image_files = existing_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "Configure the OCR pipeline for local environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ukrainian_ocr import UkrainianOCRPipeline, OCRConfig\n",
    "\n",
    "# Create configuration optimized for local environment\n",
    "config = OCRConfig()\n",
    "\n",
    "# Optimize based on available hardware\n",
    "if recommended_device == 'cuda':\n",
    "    config.device = 'cuda'\n",
    "    config.batch_size = 4  # Adjust based on GPU memory\n",
    "    print(\"üöÄ Configured for GPU processing\")\n",
    "else:\n",
    "    config.device = 'cpu'\n",
    "    config.batch_size = 1  # CPU processes one at a time\n",
    "    print(\"üíª Configured for CPU processing\")\n",
    "\n",
    "# Configure processing options\n",
    "config.verbose = True  # Enable progress bars\n",
    "config.post_processing.extract_person_regions = True  # Extract person-dense regions\n",
    "\n",
    "# NER settings\n",
    "config.ner.backend = 'spacy'\n",
    "config.ner.confidence_threshold = 0.7\n",
    "\n",
    "print(\"\\n‚öôÔ∏è Configuration settings:\")\n",
    "print(f\"  Device: {config.device}\")\n",
    "print(f\"  Batch size: {config.batch_size}\")\n",
    "print(f\"  NER backend: {config.ner.backend}\")\n",
    "print(f\"  Extract person regions: {config.post_processing.extract_person_regions}\")\n",
    "print(f\"  Verbose logging: {config.verbose}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Processing Pipeline\n",
    "\n",
    "Initialize the pipeline and process your documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OCR pipeline\n",
    "print(\"üöÄ Initializing Ukrainian OCR Pipeline...\")\n",
    "print(\"üì• This may take a moment on first run (downloading models)\")\n",
    "\n",
    "try:\n",
    "    pipeline = UkrainianOCRPipeline(\n",
    "        config=config,\n",
    "        device=recommended_device,\n",
    "        verbose=True\n",
    "    )\n",
    "    print(\"‚úÖ Pipeline initialized successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing pipeline: {e}\")\n",
    "    print(\"üí° Make sure all dependencies are installed:\")\n",
    "    print(\"   pip install transformers kraken spacy\")\n",
    "    print(\"   python -m spacy download ru_core_news_lg\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images (skip if no test images)\n",
    "if not image_files:\n",
    "    print(\"‚ö†Ô∏è No images to process. Please set up test images in the previous cell.\")\n",
    "else:\n",
    "    import time\n",
    "    \n",
    "    print(f\"üîÑ Processing {len(image_files)} image(s)...\\n\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = './test_results'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Start processing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if len(image_files) == 1:\n",
    "        # Single image processing\n",
    "        results = [pipeline.process_single_image(\n",
    "            image_files[0], \n",
    "            output_dir=output_dir,\n",
    "            save_intermediate=True\n",
    "        )]\n",
    "    else:\n",
    "        # Batch processing\n",
    "        results = pipeline.process_batch(\n",
    "            image_files, \n",
    "            output_dir=output_dir,\n",
    "            save_intermediate=True\n",
    "        )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Display results summary\n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    failed = len(results) - successful\n",
    "    \n",
    "    print(f\"\\nüéâ Processing complete!\")\n",
    "    print(f\"‚úÖ Successful: {successful}/{len(results)}\")\n",
    "    print(f\"‚ùå Failed: {failed}/{len(results)}\")\n",
    "    print(f\"‚è±Ô∏è Total time: {total_time:.1f}s\")\n",
    "    print(f\"üìä Average per image: {total_time/len(results):.1f}s\")\n",
    "    \n",
    "    # Show pipeline statistics\n",
    "    stats = pipeline.get_stats()\n",
    "    print(f\"\\nüìà Pipeline Statistics:\")\n",
    "    print(f\"  Images processed: {stats['images_processed']}\")\n",
    "    print(f\"  Total processing time: {stats['total_processing_time']:.1f}s\")\n",
    "    print(f\"  Average time per image: {stats['average_time_per_image']:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Results Analysis\n",
    "\n",
    "Analyze the processing results and view extracted entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results for each processed image\n",
    "if 'results' in locals() and results:\n",
    "    import xml.etree.ElementTree as ET\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        if result['success']:\n",
    "            print(f\"\\nüìÑ Image {i+1}: {os.path.basename(result['image_path'])}\")\n",
    "            print(f\"‚è±Ô∏è Processing time: {result['processing_time']:.2f}s\")\n",
    "            print(f\"üìè Lines detected: {result['lines_detected']}\")\n",
    "            print(f\"üìù Lines with text: {result['lines_with_text']}\")\n",
    "            \n",
    "            # Show entities if available\n",
    "            if 'entities_extracted' in result and result['entities_extracted'] > 0:\n",
    "                print(f\"üéØ Entities extracted: {result['total_entities']} in {result['entities_extracted']} lines\")\n",
    "            \n",
    "            # Show output files\n",
    "            print(f\"\\nüìÅ Output files:\")\n",
    "            for file_type, path in result['output_paths'].items():\n",
    "                if path and os.path.exists(path):\n",
    "                    size_kb = os.path.getsize(path) / 1024\n",
    "                    print(f\"  {file_type}: {os.path.basename(path)} ({size_kb:.1f}KB)\")\n",
    "                    \n",
    "            # Try to extract sample text from ALTO\n",
    "            alto_basic = result['output_paths'].get('alto_basic')\n",
    "            if alto_basic and os.path.exists(alto_basic):\n",
    "                try:\n",
    "                    tree = ET.parse(alto_basic)\n",
    "                    root = tree.getroot()\n",
    "                    \n",
    "                    # Extract text content from ALTO\n",
    "                    ns = {'alto': 'http://www.loc.gov/standards/alto/ns-v4#'}\n",
    "                    strings = root.findall('.//alto:String', ns)\n",
    "                    \n",
    "                    if strings:\n",
    "                        print(f\"\\nüìù Sample extracted text (first 5 lines):\")\n",
    "                        for j, string_elem in enumerate(strings[:5]):\n",
    "                            text = string_elem.get('CONTENT', '')\n",
    "                            if text.strip():\n",
    "                                print(f\"  {j+1}. {text}\")\n",
    "                                \n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ö†Ô∏è Could not parse ALTO file: {e}\")\n",
    "                    \n",
    "        else:\n",
    "            print(f\"\\n‚ùå Image {i+1} failed: {result.get('error', 'Unknown error')}\")\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results to analyze. Run the processing cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Visualization\n",
    "\n",
    "Display processing visualizations and person-dense regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display visualizations for successful results\n",
    "if 'results' in locals() and results:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.image as mpimg\n",
    "    from IPython.display import display, Image as IPImage\n",
    "    \n",
    "    # Display visualizations for successful results\n",
    "    for i, result in enumerate(results[:3]):  # Limit to first 3 images\n",
    "        if result['success']:\n",
    "            print(f\"\\nüé® Visualizations for Image {i+1}: {os.path.basename(result['image_path'])}\")\n",
    "            \n",
    "            # Show segmentation visualization if available\n",
    "            viz_path = result['output_paths'].get('visualization')\n",
    "            if viz_path and os.path.exists(viz_path):\n",
    "                try:\n",
    "                    plt.figure(figsize=(15, 10))\n",
    "                    img = mpimg.imread(viz_path)\n",
    "                    plt.imshow(img)\n",
    "                    plt.title(f\"Segmentation Results - {os.path.basename(result['image_path'])}\")\n",
    "                    plt.axis('off')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ö†Ô∏è Could not display segmentation visualization: {e}\")\n",
    "                    \n",
    "            # Show person region if available\n",
    "            person_regions_path = result['output_paths'].get('person_regions')\n",
    "            if person_regions_path and os.path.exists(person_regions_path):\n",
    "                try:\n",
    "                    plt.figure(figsize=(12, 8))\n",
    "                    img = mpimg.imread(person_regions_path)\n",
    "                    plt.imshow(img)\n",
    "                    plt.title(f\"Person-Dense Region - {os.path.basename(result['image_path'])}\")\n",
    "                    plt.axis('off')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚ö†Ô∏è Could not display person region: {e}\")\n",
    "            else:\n",
    "                print(\"  ‚ÑπÔ∏è No person-dense regions extracted\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results to visualize. Run the processing cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Export Results\n",
    "\n",
    "Export your processing results to different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results summary\n",
    "if 'results' in locals() and results:\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Create comprehensive results summary\n",
    "    summary = {\n",
    "        'processing_info': {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'total_images': len(results),\n",
    "            'successful': sum(1 for r in results if r['success']),\n",
    "            'failed': sum(1 for r in results if not r['success']),\n",
    "            'total_processing_time': sum(r.get('processing_time', 0) for r in results),\n",
    "            'system_info': {\n",
    "                'device_used': config.device,\n",
    "                'batch_size': config.batch_size,\n",
    "                'python_version': sys.version.split()[0],\n",
    "                'pytorch_version': torch.__version__\n",
    "            }\n",
    "        },\n",
    "        'results': results\n",
    "    }\n",
    "    \n",
    "    # Save results summary as JSON\n",
    "    summary_path = os.path.join(output_dir, 'processing_summary.json')\n",
    "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, indent=2, ensure_ascii=False, default=str)\n",
    "    \n",
    "    # Create text summary\n",
    "    text_summary_path = os.path.join(output_dir, 'processing_summary.txt')\n",
    "    with open(text_summary_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Ukrainian OCR Pipeline - Processing Summary\\n\")\n",
    "        f.write(\"=\" * 45 + \"\\n\\n\")\n",
    "        f.write(f\"Timestamp: {summary['processing_info']['timestamp']}\\n\")\n",
    "        f.write(f\"Total Images: {summary['processing_info']['total_images']}\\n\")\n",
    "        f.write(f\"Successful: {summary['processing_info']['successful']}\\n\")\n",
    "        f.write(f\"Failed: {summary['processing_info']['failed']}\\n\")\n",
    "        f.write(f\"Total Time: {summary['processing_info']['total_processing_time']:.2f}s\\n\")\n",
    "        f.write(f\"Device Used: {summary['processing_info']['system_info']['device_used']}\\n\\n\")\n",
    "        \n",
    "        # Add details for each image\n",
    "        for i, result in enumerate(results):\n",
    "            f.write(f\"Image {i+1}: {os.path.basename(result['image_path'])}\\n\")\n",
    "            if result['success']:\n",
    "                f.write(f\"  Status: Success\\n\")\n",
    "                f.write(f\"  Processing Time: {result['processing_time']:.2f}s\\n\")\n",
    "                f.write(f\"  Lines Detected: {result['lines_detected']}\\n\")\n",
    "                f.write(f\"  Lines with Text: {result['lines_with_text']}\\n\")\n",
    "                if 'entities_extracted' in result:\n",
    "                    f.write(f\"  Entities Extracted: {result.get('total_entities', 0)}\\n\")\n",
    "            else:\n",
    "                f.write(f\"  Status: Failed\\n\")\n",
    "                f.write(f\"  Error: {result.get('error', 'Unknown error')}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    print(f\"üìÑ Results exported:\")\n",
    "    print(f\"  JSON summary: {summary_path}\")\n",
    "    print(f\"  Text summary: {text_summary_path}\")\n",
    "    \n",
    "    # Show output directory contents\n",
    "    print(f\"\\nüìÅ Output directory ({output_dir}):\")\n",
    "    for root, dirs, files in os.walk(output_dir):\n",
    "        level = root.replace(output_dir, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            size_kb = os.path.getsize(file_path) / 1024\n",
    "            print(f\"{subindent}{file} ({size_kb:.1f}KB)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No results to export. Run the processing cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cleanup\n",
    "\n",
    "Clean up GPU memory and temporary resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up pipeline resources\n",
    "if 'pipeline' in locals():\n",
    "    pipeline.cleanup()\n",
    "    print(\"‚úÖ Pipeline resources cleaned up\")\n",
    "\n",
    "# Show final memory usage\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nüìä Final GPU Memory Usage:\")\n",
    "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "    cached = torch.cuda.memory_reserved() / 1024**3\n",
    "    print(f\"  Allocated: {allocated:.2f}GB\")\n",
    "    print(f\"  Cached: {cached:.2f}GB\")\n",
    "    \n",
    "    # Force cleanup\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"  ‚úÖ GPU cache cleared\")\n",
    "\n",
    "print(\"\\nüéâ Local testing complete!\")\n",
    "if 'output_dir' in locals():\n",
    "    print(f\"üìö Check the results in: {os.path.abspath(output_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Development & Testing Utilities\n",
    "\n",
    "Additional utilities for development and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick model testing function\n",
    "def test_individual_components():\n",
    "    \"\"\"Test individual pipeline components\"\"\"\n",
    "    print(\"üîß Testing individual components...\\n\")\n",
    "    \n",
    "    # Test segmentation\n",
    "    try:\n",
    "        from ukrainian_ocr.core.segmentation import KrakenSegmenter\n",
    "        import cv2\n",
    "        \n",
    "        if image_files:\n",
    "            test_img = cv2.imread(image_files[0])\n",
    "            segmenter = KrakenSegmenter(device='cpu')  # Use CPU for testing\n",
    "            lines = segmenter.segment_image(test_img)\n",
    "            print(f\"‚úÖ Segmentation: {len(lines)} lines detected\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Segmentation: No test images available\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Segmentation error: {e}\")\n",
    "    \n",
    "    # Test OCR\n",
    "    try:\n",
    "        from ukrainian_ocr.core.ocr import TrOCRProcessor\n",
    "        import numpy as np\n",
    "        \n",
    "        ocr_processor = TrOCRProcessor(device='cpu')  # Use CPU for testing\n",
    "        \n",
    "        # Create a small test image\n",
    "        test_image = np.ones((50, 200, 3), dtype=np.uint8) * 255\n",
    "        result = ocr_processor.recognize_text(test_image)\n",
    "        print(f\"‚úÖ OCR: Model loaded, test returned: '{result['text']}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå OCR error: {e}\")\n",
    "    \n",
    "    # Test NER\n",
    "    try:\n",
    "        from ukrainian_ocr.core.ner import NERExtractor\n",
    "        \n",
    "        ner_extractor = NERExtractor()\n",
    "        entities = ner_extractor.extract_entities(\"–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤ –∏–∑ –ö–∏–µ–≤–∞\")\n",
    "        print(f\"‚úÖ NER: {len(entities)} entities found in test text\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå NER error: {e}\")\n",
    "\n",
    "# Uncomment to test individual components\n",
    "# test_individual_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance benchmarking\n",
    "def benchmark_pipeline():\n",
    "    \"\"\"Benchmark pipeline performance on different settings\"\"\"\n",
    "    print(\"üìä Benchmarking pipeline performance...\\n\")\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"‚ö†Ô∏è No test images available for benchmarking\")\n",
    "        return\n",
    "    \n",
    "    test_image = image_files[0]\n",
    "    \n",
    "    # Test different configurations\n",
    "    configs_to_test = [\n",
    "        {'device': 'cpu', 'batch_size': 1, 'name': 'CPU Single'},\n",
    "    ]\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        configs_to_test.extend([\n",
    "            {'device': 'cuda', 'batch_size': 1, 'name': 'GPU Single'},\n",
    "            {'device': 'cuda', 'batch_size': 4, 'name': 'GPU Batch'},\n",
    "        ])\n",
    "    \n",
    "    for test_config in configs_to_test:\n",
    "        try:\n",
    "            print(f\"Testing {test_config['name']}...\")\n",
    "            \n",
    "            # Create test pipeline\n",
    "            test_pipeline = UkrainianOCRPipeline(\n",
    "                device=test_config['device'],\n",
    "                batch_size=test_config['batch_size'],\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Time the processing\n",
    "            import time\n",
    "            start = time.time()\n",
    "            result = test_pipeline.process_single_image(\n",
    "                test_image,\n",
    "                output_dir='./benchmark_temp',\n",
    "                save_intermediate=False\n",
    "            )\n",
    "            end = time.time()\n",
    "            \n",
    "            if result['success']:\n",
    "                print(f\"  ‚úÖ {test_config['name']}: {end-start:.2f}s\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå {test_config['name']}: Failed\")\n",
    "            \n",
    "            # Cleanup\n",
    "            test_pipeline.cleanup()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå {test_config['name']}: Error - {e}\")\n",
    "    \n",
    "    # Cleanup benchmark temp directory\n",
    "    import shutil\n",
    "    if os.path.exists('./benchmark_temp'):\n",
    "        shutil.rmtree('./benchmark_temp')\n",
    "\n",
    "# Uncomment to run benchmark\n",
    "# benchmark_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "**What you can do with the results:**\n",
    "\n",
    "1. **ALTO XML files** - Import into eScriptorium or other document analysis tools\n",
    "2. **Enhanced ALTO** - Contains named entity annotations for persons and locations\n",
    "3. **Person-dense regions** - Cropped images focusing on genealogically valuable content\n",
    "4. **Entity extraction** - Use the identified persons and locations for genealogical research\n",
    "\n",
    "**For production use:**\n",
    "- Use the CLI interface: `ukrainian-ocr --help`\n",
    "- Customize configuration files\n",
    "- Integrate with existing workflows\n",
    "- Process larger batches of documents\n",
    "\n",
    "**Development:**\n",
    "- Modify component implementations in `ukrainian_ocr/core/`\n",
    "- Add custom NER models\n",
    "- Extend ALTO XML generation\n",
    "- Add new post-processing features\n",
    "\n",
    "**Need help?**\n",
    "- Check the package documentation\n",
    "- Review the configuration options\n",
    "- Test individual components using the utilities above\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}