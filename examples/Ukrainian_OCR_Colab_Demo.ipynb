{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ğŸ‡ºğŸ‡¦ Ukrainian OCR Pipeline - Google Colab Demo\n",
    "\n",
    "This notebook demonstrates the **Ukrainian OCR Pipeline Package** in Google Colab environment.\n",
    "\n",
    "## Features:\n",
    "- **Automatic GPU Detection** and optimization for Colab T4/V100/A100\n",
    "- **GitHub Integration** with automatic repository cloning\n",
    "- **Two-Stage Processing**: Segmentation â†’ Recognition & Enhancement\n",
    "- **Complete Pipeline**: Kraken â†’ TrOCR â†’ NER â†’ Surname Matching â†’ Enhanced ALTO\n",
    "- **Download Support**: Results automatically downloadable from Colab\n",
    "\n",
    "## Quick Start:\n",
    "1. **Upload your document** using the file uploader\n",
    "2. **Run all cells** for complete processing\n",
    "3. **Download results** from the generated files section\n",
    "\n",
    "---\n",
    "**âš¡ Optimized for Google Colab Free/Pro/Pro+ GPUs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## ğŸ”§ Environment Setup & Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're in Google Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸš€ Running in Google Colab\")\n",
    "    \n",
    "    # Mount Google Drive (optional)\n",
    "    from google.colab import drive\n",
    "    try:\n",
    "        drive.mount('/content/drive')\n",
    "        print(\"âœ… Google Drive mounted\")\n",
    "    except:\n",
    "        print(\"âš ï¸ Google Drive mount failed (optional)\")\n",
    "    \n",
    "    # Install system dependencies\n",
    "    print(\"ğŸ“¦ Installing system dependencies...\")\n",
    "    !apt-get update -qq\n",
    "    !apt-get install -y -qq libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1\n",
    "    \n",
    "    # Clone the repository\n",
    "    print(\"ğŸ“¥ Cloning Ukrainian OCR repository...\")\n",
    "    !git clone https://github.com/your-repo/ukrainian-ocr-package.git /content/ukrainian_ocr_package\n",
    "    \n",
    "    # Install the package\n",
    "    print(\"âš™ï¸ Installing Ukrainian OCR package...\")\n",
    "    !cd /content/ukrainian_ocr_package && pip install -e .\n",
    "    \n",
    "    print(\"âœ… Installation complete!\")\n",
    "else:\n",
    "    print(\"ğŸ’» Running in local environment\")\n",
    "    print(\"âš ï¸ This notebook is optimized for Google Colab\")\n",
    "    print(\"ğŸ“ For local development, use Ukrainian_OCR_Local_Demo.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Package Import & Hardware Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Core libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Ukrainian OCR Package\n",
    "if IN_COLAB:\n",
    "    sys.path.insert(0, '/content/ukrainian_ocr_package')\n",
    "\n",
    "from ukrainian_ocr import UkrainianOCRPipeline\n",
    "from ukrainian_ocr.core.config import OCRPipelineConfig\n",
    "\n",
    "print(f\"âœ… Ukrainian OCR Package loaded\")\n",
    "print(f\"ğŸ“ Package location: {__import__('ukrainian_ocr').__file__}\")\n",
    "\n",
    "# Google Colab specific imports\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ–¥ï¸ Hardware Detection:\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# GPU detection optimized for Colab\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"âœ… GPU: {gpu_name} ({gpu_memory:.1f}GB VRAM)\")\n",
    "    \n",
    "    # Optimize for different Colab GPU types\n",
    "    if 'T4' in gpu_name:\n",
    "        device = 'cuda'\n",
    "        batch_size = 4  # Conservative for T4\n",
    "        print(\"ğŸ¯ Optimized for Colab T4 GPU\")\n",
    "    elif 'V100' in gpu_name or 'A100' in gpu_name:\n",
    "        device = 'cuda'\n",
    "        batch_size = 8  # More aggressive for Pro/Pro+\n",
    "        print(\"ğŸ¯ Optimized for Colab Pro/Pro+ GPU\")\n",
    "    else:\n",
    "        device = 'cuda'\n",
    "        batch_size = 6  # Default for other GPUs\n",
    "        print(\"ğŸ¯ Optimized for GPU\")\n",
    "else:\n",
    "    print(\"âš ï¸ GPU not available - using CPU (will be slower)\")\n",
    "    device = 'cpu'\n",
    "    batch_size = 1\n",
    "\n",
    "print(f\"ğŸ¯ Selected device: {device}\")\n",
    "print(f\"ğŸ“¦ Batch size: {batch_size}\")\n",
    "\n",
    "# Create Colab-optimized configuration\n",
    "config = {\n",
    "    'device': device,\n",
    "    'batch_size': batch_size,\n",
    "    'verbose': True,\n",
    "    'save_intermediate': True,\n",
    "    \n",
    "    'ocr': {\n",
    "        'model_path': 'cyrillic-trocr/trocr-handwritten-cyrillic',\n",
    "        'device': device,\n",
    "        'batch_size': batch_size\n",
    "    },\n",
    "    \n",
    "    'ner': {\n",
    "        'backend': 'spacy',  # Most stable for Colab\n",
    "        'device': device,\n",
    "        'confidence_threshold': 0.7\n",
    "    },\n",
    "    \n",
    "    'surname_matching': {\n",
    "        'enabled': True,\n",
    "        'threshold': 0.8,\n",
    "        'use_phonetic': True,\n",
    "        'export_matches': True,\n",
    "        'surnames': [\n",
    "            'Ğ¨ĞµĞ²Ñ‡ĞµĞ½ĞºĞ¾', 'ĞšĞ¾Ğ²Ğ°Ğ»ĞµĞ½ĞºĞ¾', 'Ğ‘Ğ¾Ğ½Ğ´Ğ°Ñ€ĞµĞ½ĞºĞ¾', 'Ğ¢ĞºĞ°Ñ‡ĞµĞ½ĞºĞ¾', 'ĞšÑ€Ğ°Ğ²Ñ‡ĞµĞ½ĞºĞ¾',\n",
    "            'ĞŸĞµÑ‚Ñ€ĞµĞ½ĞºĞ¾', 'Ğ†Ğ²Ğ°Ğ½ĞµĞ½ĞºĞ¾', 'ĞœĞ¸Ñ…Ğ°Ğ¹Ğ»ĞµĞ½ĞºĞ¾', 'Ğ’Ğ°ÑĞ¸Ğ»ĞµĞ½ĞºĞ¾', 'Ğ“Ñ€Ğ¸Ğ³Ğ¾Ñ€ĞµĞ½ĞºĞ¾',\n",
    "            'ĞšĞ¾Ğ²Ğ°Ğ»ÑŒÑ‡ÑƒĞº', 'Ğ¡Ğ°Ğ²Ñ‡ĞµĞ½ĞºĞ¾', 'Ğ›ĞµĞ²Ñ‡ĞµĞ½ĞºĞ¾', 'ĞŸĞ°Ğ²Ğ»ĞµĞ½ĞºĞ¾', 'ĞœĞ°Ñ€Ñ‡ĞµĞ½ĞºĞ¾',\n",
    "            'ĞœĞµĞ»ÑŒĞ½Ğ¸Ğº', 'ĞšĞ¾Ğ²Ğ°Ğ»ÑŒ', 'Ğ“Ğ¾Ğ½Ñ‡Ğ°Ñ€', 'ĞšÑ€Ğ°Ğ²ĞµÑ†ÑŒ', 'Ğ¨Ğ²ĞµÑ†ÑŒ',\n",
    "            'Ğ–ÑƒĞº', 'ĞšĞ¾Ğ·Ğ»Ğ¾Ğ²', 'ĞœĞ¾Ñ€Ğ¾Ğ·', 'Ğ¢ĞµÑ€ĞµÑ‰ĞµĞ½ĞºĞ¾', 'Ğ Ğ¸Ğ±Ğ°Ğ»ĞºĞ¾'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'post_processing': {\n",
    "        'extract_person_regions': True,\n",
    "        'clustering_eps': 300\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ… Configuration optimized for Google Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## ğŸ“¤ Upload Document for Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    print(\"ğŸ“¤ Upload your Ukrainian document (JPG, PNG, TIFF):\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        # Get the uploaded file\n",
    "        test_image_path = list(uploaded.keys())[0]\n",
    "        print(f\"âœ… Document uploaded: {test_image_path}\")\n",
    "        \n",
    "        # Move to content directory for easier access\n",
    "        import shutil\n",
    "        dest_path = f\"/content/{test_image_path}\"\n",
    "        if os.path.exists(test_image_path) and test_image_path != dest_path:\n",
    "            shutil.move(test_image_path, dest_path)\n",
    "            test_image_path = dest_path\n",
    "    else:\n",
    "        print(\"âŒ No file uploaded\")\n",
    "        test_image_path = None\n",
    "else:\n",
    "    # For local testing\n",
    "    test_image_paths = [\n",
    "        \"./sample_document.jpg\",\n",
    "        \"../test_images/ukrainian_document.jpg\"\n",
    "    ]\n",
    "    \n",
    "    test_image_path = None\n",
    "    for path in test_image_paths:\n",
    "        if os.path.exists(path):\n",
    "            test_image_path = path\n",
    "            break\n",
    "\n",
    "if test_image_path and os.path.exists(test_image_path):\n",
    "    # Display document information\n",
    "    image_size = os.path.getsize(test_image_path) / (1024 * 1024)\n",
    "    \n",
    "    with Image.open(test_image_path) as img:\n",
    "        width, height = img.size\n",
    "        \n",
    "        print(f\"ğŸ“„ Document: {os.path.basename(test_image_path)}\")\n",
    "        print(f\"ğŸ“Š Size: {image_size:.1f} MB\")\n",
    "        print(f\"ğŸ“ Dimensions: {width} x {height} pixels\")\n",
    "        print(f\"ğŸ“ Format: {img.format}\")\n",
    "        \n",
    "        # Display preview\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Document: {os.path.basename(test_image_path)}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"âŒ No document available for processing\")\n",
    "    if IN_COLAB:\n",
    "        print(\"Please run the upload cell above\")\n",
    "    else:\n",
    "        print(\"Please add a document to the test_image_paths list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## ğŸ Stage 1: Document Segmentation & Basic ALTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not test_image_path or not os.path.exists(test_image_path):\n",
    "    print(\"âŒ Cannot proceed without a document. Please upload a file.\")\n",
    "else:\n",
    "    print(\"ğŸš€ STAGE 1: Document Segmentation & Basic ALTO Creation\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    pipeline_config = OCRPipelineConfig.from_dict(config)\n",
    "    \n",
    "    # Update for Colab environment\n",
    "    pipeline_config.update_for_colab()\n",
    "    \n",
    "    pipeline = UkrainianOCRPipeline(config=pipeline_config)\n",
    "    \n",
    "    print(f\"âœ… Pipeline ready (device: {pipeline.device})\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(\"/content/ukrainian_ocr_output\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Load and process image\n",
    "    print(\"\\nğŸ” Kraken Segmentation...\")\n",
    "    if device == 'cpu':\n",
    "        print(\"â³ CPU processing detected - this may take a few minutes\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize components\n",
    "    pipeline._init_components()\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(test_image_path)\n",
    "    \n",
    "    # Segment image\n",
    "    lines = pipeline.segmenter.segment_image(image)\n",
    "    seg_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"âœ… Segmentation complete: {seg_time:.2f}s\")\n",
    "    print(f\"ğŸ“Š Detected {len(lines)} text lines\")\n",
    "    \n",
    "    # Create basic ALTO XML\n",
    "    print(\"\\nğŸ“„ Creating basic ALTO XML...\")\n",
    "    basic_alto_xml = pipeline._create_alto_xml(Path(test_image_path), image, lines)\n",
    "    \n",
    "    basic_alto_path = output_dir / f\"{Path(test_image_path).stem}_basic_alto.xml\"\n",
    "    with open(basic_alto_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(basic_alto_xml)\n",
    "    \n",
    "    print(f\"âœ… Basic ALTO created: {basic_alto_path}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    print(\"\\nğŸ¨ Creating segmentation visualization...\")\n",
    "    vis_image = image.copy()\n",
    "    colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0)]\n",
    "    \n",
    "    for idx, line in enumerate(lines[:200]):  # Show first 200 lines to avoid clutter\n",
    "        color = colors[idx % len(colors)]\n",
    "        polygon = line.get('polygon', [])\n",
    "        if polygon and len(polygon) >= 3:\n",
    "            pts = np.array(polygon, np.int32)\n",
    "            cv2.polylines(vis_image, [pts], True, color, 2)\n",
    "    \n",
    "    # Save and display visualization\n",
    "    vis_path = output_dir / f\"{Path(test_image_path).stem}_segmentation.png\"\n",
    "    cv2.imwrite(str(vis_path), vis_image)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Segmentation: {len(lines)} lines detected\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"âœ… Stage 1 complete - ready for text recognition\")\n",
    "    \n",
    "    # Store results for Stage 2\n",
    "    stage1_results = {\n",
    "        'image': image,\n",
    "        'lines': lines,\n",
    "        'segmentation_time': seg_time,\n",
    "        'basic_alto_path': basic_alto_path,\n",
    "        'output_dir': output_dir\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## ğŸ¤– Stage 2: Text Recognition, NER & Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'stage1_results' not in locals():\n",
    "    print(\"âŒ Please run Stage 1 first\")\n",
    "else:\n",
    "    print(\"ğŸš€ STAGE 2: Text Recognition, NER & Enhancement\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    image = stage1_results['image']\n",
    "    lines = stage1_results['lines']\n",
    "    output_dir = stage1_results['output_dir']\n",
    "    \n",
    "    print(f\"ğŸ“„ Processing {len(lines)} lines\")\n",
    "    \n",
    "    # Text Recognition with TrOCR\n",
    "    print(\"\\nğŸ¤– TrOCR Text Recognition...\")\n",
    "    if device == 'cpu':\n",
    "        print(\"â³ CPU processing - this will take several minutes\")\n",
    "    elif 'T4' in torch.cuda.get_device_name(0):\n",
    "        print(\"âš¡ T4 GPU detected - optimized processing\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    lines_with_text = pipeline.ocr_processor.process_lines(image, lines)\n",
    "    ocr_time = time.time() - start_time\n",
    "    \n",
    "    recognized_lines = [l for l in lines_with_text if l.get('text', '').strip()]\n",
    "    print(f\"âœ… OCR complete: {ocr_time:.2f}s\")\n",
    "    print(f\"ğŸ“Š Text in {len(recognized_lines)}/{len(lines)} lines\")\n",
    "    \n",
    "    # Show sample text\n",
    "    print(\"\\nğŸ“ Sample recognized text:\")\n",
    "    for i, line in enumerate(recognized_lines[:8]):\n",
    "        text = line.get('text', '')\n",
    "        conf = line.get('confidence', 0)\n",
    "        print(f\"  {i+1}. '{text}' ({conf:.2f})\")\n",
    "    \n",
    "    # Named Entity Recognition\n",
    "    print(\"\\nğŸ·ï¸ Named Entity Recognition...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ner_results = pipeline.ner_extractor.extract_entities_from_lines(lines_with_text)\n",
    "    ner_time = time.time() - start_time\n",
    "    \n",
    "    all_entities = ner_results.get('all_entities', [])\n",
    "    print(f\"âœ… NER complete: {ner_time:.2f}s\")\n",
    "    print(f\"ğŸ·ï¸ Found {len(all_entities)} entities\")\n",
    "    print(f\"ğŸ§  Backend: {ner_results.get('backend', 'unknown')}\")\n",
    "    \n",
    "    if all_entities:\n",
    "        # Group by type\n",
    "        entity_types = {}\n",
    "        for entity in all_entities:\n",
    "            label = entity.get('label', 'UNKNOWN')\n",
    "            entity_types[label] = entity_types.get(label, 0) + 1\n",
    "        \n",
    "        print(\"\\nEntity types:\")\n",
    "        for etype, count in entity_types.items():\n",
    "            print(f\"  {etype}: {count}\")\n",
    "        \n",
    "        print(\"\\nSample entities:\")\n",
    "        for entity in all_entities[:8]:\n",
    "            print(f\"  '{entity.get('text', '')}' -> {entity.get('label', '')}\")\n",
    "    \n",
    "    # Surname Matching\n",
    "    print(\"\\nğŸ‘¥ Surname Matching...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    surname_matches = pipeline.surname_matcher.find_in_lines(lines_with_text)\n",
    "    surname_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"âœ… Surname matching: {surname_time:.2f}s\")\n",
    "    print(f\"ğŸ‘¥ Found {len(surname_matches)} matches\")\n",
    "    \n",
    "    if surname_matches:\n",
    "        unique_surnames = set(m.matched_surname for m in surname_matches)\n",
    "        print(f\"ğŸ“Š Unique surnames: {len(unique_surnames)}\")\n",
    "        \n",
    "        print(\"\\nSample matches:\")\n",
    "        for match in surname_matches[:8]:\n",
    "            print(f\"  '{match.found_text}' -> '{match.matched_surname}' ({match.confidence:.2f})\")\n",
    "        \n",
    "        # Export matches\n",
    "        matches_file = output_dir / f\"{Path(test_image_path).stem}_surnames.json\"\n",
    "        pipeline.surname_matcher.export_matches(surname_matches, str(matches_file))\n",
    "        print(f\"ğŸ’¾ Surnames saved: {matches_file}\")\n",
    "    \n",
    "    # Create Enhanced ALTO\n",
    "    print(\"\\nâœ¨ Creating Enhanced ALTO...\")\n",
    "    \n",
    "    # Complete ALTO with text\n",
    "    complete_alto_xml = pipeline._create_alto_xml(Path(test_image_path), image, lines_with_text)\n",
    "    complete_alto_path = output_dir / f\"{Path(test_image_path).stem}_complete_alto.xml\"\n",
    "    \n",
    "    with open(complete_alto_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(complete_alto_xml)\n",
    "    \n",
    "    print(f\"âœ… Complete ALTO: {complete_alto_path}\")\n",
    "    \n",
    "    # Enhanced ALTO with NER (if entities found)\n",
    "    enhanced_alto_path = None\n",
    "    if all_entities:\n",
    "        # Map entities to lines\n",
    "        entities_by_line_id = {}\n",
    "        for idx, line in enumerate(lines_with_text):\n",
    "            line_id = f\"line_{idx}\"\n",
    "            line_text = line.get('text', '')\n",
    "            \n",
    "            line_entities = []\n",
    "            for entity in all_entities:\n",
    "                if entity.get('text', '') in line_text:\n",
    "                    line_entities.append(entity)\n",
    "            \n",
    "            if line_entities:\n",
    "                entities_by_line_id[line_id] = {'entities': line_entities}\n",
    "        \n",
    "        if entities_by_line_id:\n",
    "            enhanced_alto_path = output_dir / f\"{Path(test_image_path).stem}_enhanced_alto.xml\"\n",
    "            pipeline.alto_enhancer.enhance_alto_with_ner(\n",
    "                str(complete_alto_path), entities_by_line_id, str(enhanced_alto_path)\n",
    "            )\n",
    "            print(f\"âœ… Enhanced ALTO: {enhanced_alto_path}\")\n",
    "    \n",
    "    # Final Summary\n",
    "    total_time = stage1_results['segmentation_time'] + ocr_time + ner_time + surname_time\n",
    "    \n",
    "    print(\"\\nğŸ“Š PROCESSING COMPLETE\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"â±ï¸ Total time: {total_time:.2f}s\")\n",
    "    print(f\"ğŸ” Lines detected: {len(lines)}\")\n",
    "    print(f\"ğŸ“ Lines with text: {len(recognized_lines)}\")\n",
    "    print(f\"ğŸ·ï¸ Entities found: {len(all_entities)}\")\n",
    "    print(f\"ğŸ‘¥ Surname matches: {len(surname_matches)}\")\n",
    "    \n",
    "    # List output files\n",
    "    print(\"\\nğŸ“ Generated files:\")\n",
    "    generated_files = []\n",
    "    for file_path in output_dir.glob(\"*\"):\n",
    "        size_kb = file_path.stat().st_size / 1024\n",
    "        print(f\"  ğŸ“„ {file_path.name} ({size_kb:.1f} KB)\")\n",
    "        generated_files.append(str(file_path))\n",
    "    \n",
    "    print(f\"\\nâœ… All files saved in: {output_dir}\")\n",
    "    print(\"ğŸ‰ Ukrainian OCR processing completed!\")\n",
    "    \n",
    "    # Store for download section\n",
    "    processing_results = {\n",
    "        'output_dir': output_dir,\n",
    "        'generated_files': generated_files,\n",
    "        'total_time': total_time,\n",
    "        'stats': {\n",
    "            'lines_detected': len(lines),\n",
    "            'lines_with_text': len(recognized_lines),\n",
    "            'entities_found': len(all_entities),\n",
    "            'surname_matches': len(surname_matches)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Download Results (Colab Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB and 'processing_results' in locals():\n",
    "    print(\"ğŸ“¥ Download your OCR results:\")\n",
    "    \n",
    "    output_dir = processing_results['output_dir']\n",
    "    \n",
    "    # Create a zip file with all results\n",
    "    import zipfile\n",
    "    zip_path = \"/content/ukrainian_ocr_results.zip\"\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        for file_path in output_dir.glob(\"*\"):\n",
    "            zipf.write(file_path, file_path.name)\n",
    "    \n",
    "    print(f\"ğŸ“¦ Created results archive: {zip_path}\")\n",
    "    \n",
    "    # Download the zip file\n",
    "    files.download(zip_path)\n",
    "    \n",
    "    # Also offer individual file downloads\n",
    "    print(\"\\nğŸ“„ Or download individual files:\")\n",
    "    \n",
    "    # Create download buttons for each file\n",
    "    for file_path in sorted(output_dir.glob(\"*\")):\n",
    "        file_size = file_path.stat().st_size / 1024\n",
    "        print(f\"\\nğŸ“„ {file_path.name} ({file_size:.1f} KB)\")\n",
    "        \n",
    "        # Create download button\n",
    "        display(HTML(f'''\n",
    "        <button onclick=\"window.open('/files/{file_path}', '_blank')\">\n",
    "            Download {file_path.name}\n",
    "        </button>\n",
    "        '''))\n",
    "    \n",
    "    print(\"\\nâœ… All files are ready for download!\")\n",
    "    \n",
    "elif IN_COLAB:\n",
    "    print(\"âŒ No processing results found. Please run the processing cells first.\")\n",
    "else:\n",
    "    print(\"ğŸ’» Running locally - files are saved to the output directory\")\n",
    "    if 'processing_results' in locals():\n",
    "        print(f\"ğŸ“ Results saved in: {processing_results['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Results Summary & Usage Tips\n",
    "\n",
    "### Generated Files:\n",
    "- **Basic ALTO XML**: Segmentation with coordinates only\n",
    "- **Complete ALTO XML**: Full transcription with confidence scores  \n",
    "- **Enhanced ALTO XML**: With NER semantic annotations (if entities found)\n",
    "- **Surname Matches JSON**: Genealogical findings with fuzzy matching\n",
    "- **Segmentation PNG**: Visual representation of detected text lines\n",
    "\n",
    "### Google Colab Tips:\n",
    "1. **GPU Usage**: This notebook automatically detects and optimizes for T4/V100/A100 GPUs\n",
    "2. **Runtime Management**: Long processing may timeout - save intermediate results\n",
    "3. **File Persistence**: Files are saved in `/content/` and will be lost when runtime disconnects\n",
    "4. **Memory Management**: Large documents may require Pro/Pro+ for sufficient RAM\n",
    "\n",
    "### Next Steps:\n",
    "1. **Review ALTO files** in XML editor or import into eScriptorium\n",
    "2. **Analyze surname matches** for genealogical research projects\n",
    "3. **Process multiple documents** by re-running with different uploads\n",
    "4. **Customize surname lists** by modifying the configuration above\n",
    "5. **Adjust confidence thresholds** for better precision/recall balance\n",
    "\n",
    "### Performance Optimization:\n",
    "- **Batch Processing**: Upload multiple documents and process in sequence\n",
    "- **Model Caching**: Models are cached between runs in the same session\n",
    "- **GPU Memory**: Restart runtime if you encounter CUDA out-of-memory errors\n",
    "- **Image Size**: Very large images may need resizing for optimal processing\n",
    "\n",
    "---\n",
    "**ğŸ‡ºğŸ‡¦ Ukrainian OCR Pipeline** - Optimized for Google Colab environments\n",
    "\n",
    "**ğŸ”— Repository**: [GitHub Repository Link]\n",
    "\n",
    "**ğŸ“š Documentation**: [Package Documentation Link]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}