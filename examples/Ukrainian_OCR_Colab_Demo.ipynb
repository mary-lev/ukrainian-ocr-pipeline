{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukrainian-ocr-title"
      },
      "source": [
        "# üá∫üá¶ Ukrainian OCR Pipeline - Google Colab Demo\n",
        "\n",
        "High-performance OCR pipeline for historical Ukrainian documents with Named Entity Recognition (NER).\n",
        "\n",
        "**Features:**\n",
        "- ‚ö° GPU-accelerated TrOCR for Cyrillic handwriting\n",
        "- üéØ Named Entity Recognition for persons and locations\n",
        "- üìã ALTO XML output for archival standards\n",
        "- üé® Person-dense region extraction\n",
        "- üìä Progress tracking and performance monitoring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-section"
      },
      "source": [
        "## üöÄ Setup and Installation\n",
        "\n",
        "First, let's install the Ukrainian OCR pipeline package and check GPU availability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-package"
      },
      "outputs": [],
      "source": [
        "# Install the Ukrainian OCR pipeline package\n",
        "!pip install ukrainian-ocr-pipeline[colab] --quiet\n",
        "\n",
        "# Install additional dependencies for Colab\n",
        "!pip install ipywidgets --quiet\n",
        "\n",
        "print(\"‚úÖ Installation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check-gpu"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability and setup\n",
        "import ukrainian_ocr\n",
        "from ukrainian_ocr.utils.gpu import check_gpu_availability, setup_colab_gpu\n",
        "\n",
        "# Check GPU\n",
        "gpu_info = setup_colab_gpu()\n",
        "\n",
        "if gpu_info['cuda_available']:\n",
        "    print(f\"üéâ GPU detected: {gpu_info['gpu_names'][0]}\")\n",
        "    print(f\"üíæ GPU Memory: {gpu_info['gpu_memory'][0]:.1f}GB\")\n",
        "    print(f\"üî• Recommended device: {gpu_info['recommended_device']}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected. Enable GPU: Runtime -> Change runtime type -> GPU\")\n",
        "    print(\"üíª Will use CPU (slower processing)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload-section"
      },
      "source": [
        "## üìÅ Upload Images\n",
        "\n",
        "Upload your historical Ukrainian document images for processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload-images"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Create upload directory\n",
        "os.makedirs('/content/images', exist_ok=True)\n",
        "\n",
        "# Upload files\n",
        "print(\"üì§ Select your historical document images to upload:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move uploaded files to images directory\n",
        "for filename in uploaded.keys():\n",
        "    os.rename(filename, f'/content/images/{filename}')\n",
        "    print(f\"‚úÖ Uploaded: {filename}\")\n",
        "\n",
        "# List uploaded files\n",
        "image_files = [f'/content/images/{f}' for f in os.listdir('/content/images')]\n",
        "print(f\"\\nüìä Total images uploaded: {len(image_files)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config-section"
      },
      "source": [
        "## ‚öôÔ∏è Configuration\n",
        "\n",
        "Configure the OCR pipeline for optimal performance in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-config"
      },
      "outputs": [],
      "source": [
        "from ukrainian_ocr import UkrainianOCRPipeline, OCRConfig\n",
        "\n",
        "# Create optimized configuration for Colab\n",
        "config = OCRConfig()\n",
        "config.update_for_colab()  # Optimize for Colab environment\n",
        "\n",
        "# Customize settings if needed\n",
        "config.verbose = True  # Enable progress bars\n",
        "config.save_intermediate = True  # Save visualization images\n",
        "config.post_processing.extract_person_regions = True  # Extract person-dense regions\n",
        "\n",
        "print(\"‚öôÔ∏è Configuration settings:\")\n",
        "print(f\"  Device: {config.device}\")\n",
        "print(f\"  Batch size: {config.batch_size}\")\n",
        "print(f\"  NER backend: {config.ner.backend}\")\n",
        "print(f\"  Extract person regions: {config.post_processing.extract_person_regions}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "processing-section"
      },
      "source": [
        "## üîÑ Processing Pipeline\n",
        "\n",
        "Initialize the pipeline and process your documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "init-pipeline"
      },
      "outputs": [],
      "source": [
        "# Initialize the OCR pipeline\n",
        "print(\"üöÄ Initializing Ukrainian OCR Pipeline...\")\n",
        "pipeline = UkrainianOCRPipeline(\n",
        "    config=config,\n",
        "    device='auto',  # Auto-detect best device\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Pipeline initialized successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "process-images"
      },
      "outputs": [],
      "source": [
        "# Process all uploaded images\n",
        "import time\n",
        "\n",
        "print(f\"üîÑ Processing {len(image_files)} image(s)...\\n\")\n",
        "\n",
        "# Create output directory\n",
        "output_dir = '/content/ocr_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Start processing\n",
        "start_time = time.time()\n",
        "\n",
        "if len(image_files) == 1:\n",
        "    # Single image processing\n",
        "    results = [pipeline.process_single_image(\n",
        "        image_files[0], \n",
        "        output_dir=output_dir,\n",
        "        save_intermediate=True\n",
        "    )]\n",
        "else:\n",
        "    # Batch processing\n",
        "    results = pipeline.process_batch(\n",
        "        image_files, \n",
        "        output_dir=output_dir,\n",
        "        save_intermediate=True\n",
        "    )\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "# Display results summary\n",
        "successful = sum(1 for r in results if r['success'])\n",
        "failed = len(results) - successful\n",
        "\n",
        "print(f\"\\nüéâ Processing complete!\")\n",
        "print(f\"‚úÖ Successful: {successful}/{len(results)}\")\n",
        "print(f\"‚ùå Failed: {failed}/{len(results)}\")\n",
        "print(f\"‚è±Ô∏è Total time: {total_time:.1f}s\")\n",
        "print(f\"üìä Average per image: {total_time/len(results):.1f}s\")\n",
        "\n",
        "# Show pipeline statistics\n",
        "stats = pipeline.get_stats()\n",
        "print(f\"\\nüìà Pipeline Statistics:\")\n",
        "print(f\"  Images processed: {stats['images_processed']}\")\n",
        "print(f\"  Total processing time: {stats['total_processing_time']:.1f}s\")\n",
        "print(f\"  Average time per image: {stats['average_time_per_image']:.1f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results-section"
      },
      "source": [
        "## üìä Results Analysis\n",
        "\n",
        "Analyze the processing results and view extracted entities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "analyze-results"
      },
      "outputs": [],
      "source": [
        "# Analyze results for each processed image\n",
        "from IPython.display import display, Image, HTML\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "for i, result in enumerate(results):\n",
        "    if result['success']:\n",
        "        print(f\"\\nüìÑ Image {i+1}: {result['image_path']}\")\n",
        "        print(f\"‚è±Ô∏è Processing time: {result['processing_time']:.2f}s\")\n",
        "        print(f\"üìè Lines detected: {result['lines_detected']}\")\n",
        "        print(f\"üìù Lines with text: {result['lines_with_text']}\")\n",
        "        \n",
        "        # Show output files\n",
        "        print(f\"\\nüìÅ Output files:\")\n",
        "        for file_type, path in result['output_paths'].items():\n",
        "            if path and os.path.exists(path):\n",
        "                size_mb = os.path.getsize(path) / 1024 / 1024\n",
        "                print(f\"  {file_type}: {os.path.basename(path)} ({size_mb:.1f}MB)\")\n",
        "                \n",
        "        # Try to extract entities from enhanced ALTO\n",
        "        alto_enhanced = result['output_paths'].get('alto_enhanced')\n",
        "        if alto_enhanced and os.path.exists(alto_enhanced):\n",
        "            try:\n",
        "                tree = ET.parse(alto_enhanced)\n",
        "                root = tree.getroot()\n",
        "                \n",
        "                # Count entity lines\n",
        "                person_lines = len(root.findall('.//*[@ENTITY_TYPES=\"PERSON\"]'))\n",
        "                location_lines = len(root.findall('.//*[@ENTITY_TYPES=\"LOCATION\"]'))\n",
        "                \n",
        "                print(f\"\\nüéØ Entities extracted:\")\n",
        "                print(f\"  üë§ Person lines: {person_lines}\")\n",
        "                print(f\"  üìç Location lines: {location_lines}\")\n",
        "                \n",
        "                # Check for person-dense regions\n",
        "                dense_blocks = root.findall('.//TextBlock[@PERSON_LINES_COUNT]')\n",
        "                if dense_blocks:\n",
        "                    for block in dense_blocks:\n",
        "                        person_count = block.get('PERSON_LINES_COUNT', 0)\n",
        "                        print(f\"  üéØ Person-dense region: {person_count} person lines\")\n",
        "                        \n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ö†Ô∏è Could not parse ALTO file: {e}\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå Image {i+1} failed: {result.get('error', 'Unknown error')}\")\n",
        "        \n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization-section"
      },
      "source": [
        "## üé® Visualization\n",
        "\n",
        "Display processing visualizations and person-dense regions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "show-visualizations"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Image as IPImage, HTML\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Display visualizations for successful results\n",
        "for i, result in enumerate(results[:3]):  # Limit to first 3 images\n",
        "    if result['success']:\n",
        "        print(f\"\\nüé® Visualizations for Image {i+1}\")\n",
        "        \n",
        "        # Show segmentation visualization if available\n",
        "        viz_path = result['output_paths'].get('visualization')\n",
        "        if viz_path and os.path.exists(viz_path):\n",
        "            try:\n",
        "                plt.figure(figsize=(12, 8))\n",
        "                img = mpimg.imread(viz_path)\n",
        "                plt.imshow(img)\n",
        "                plt.title(f\"Segmentation Results - {os.path.basename(result['image_path'])}\")\n",
        "                plt.axis('off')\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ö†Ô∏è Could not display visualization: {e}\")\n",
        "                \n",
        "        # Show person region if available\n",
        "        person_regions_path = result['output_paths'].get('person_regions')\n",
        "        if person_regions_path and os.path.exists(person_regions_path):\n",
        "            try:\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                img = mpimg.imread(person_regions_path)\n",
        "                plt.imshow(img)\n",
        "                plt.title(f\"Person-Dense Region - {os.path.basename(result['image_path'])}\")\n",
        "                plt.axis('off')\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "            except Exception as e:\n",
        "                print(f\"  ‚ö†Ô∏è Could not display person region: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download-section"
      },
      "source": [
        "## üíæ Download Results\n",
        "\n",
        "Package and download your processing results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download-results"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# Create a zip file with all results\n",
        "zip_path = '/content/ukrainian_ocr_results.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    # Add all files from results directory\n",
        "    for root, dirs, files in os.walk(output_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            arc_path = os.path.relpath(file_path, '/content')\n",
        "            zipf.write(file_path, arc_path)\n",
        "\n",
        "zip_size_mb = os.path.getsize(zip_path) / 1024 / 1024\n",
        "print(f\"üì¶ Created results archive: ukrainian_ocr_results.zip ({zip_size_mb:.1f}MB)\")\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_path)\n",
        "print(\"‚úÖ Results downloaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleanup-section"
      },
      "source": [
        "## üßπ Cleanup\n",
        "\n",
        "Clean up GPU memory and temporary files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cleanup"
      },
      "outputs": [],
      "source": [
        "# Clean up pipeline resources\n",
        "pipeline.cleanup()\n",
        "\n",
        "# Show final memory usage\n",
        "from ukrainian_ocr.utils.gpu import monitor_gpu_memory\n",
        "\n",
        "if gpu_info['cuda_available']:\n",
        "    memory_stats = monitor_gpu_memory()\n",
        "    for gpu_id, stats in memory_stats.items():\n",
        "        print(f\"üìä {gpu_id.upper()} Memory Usage:\")\n",
        "        print(f\"  Allocated: {stats['allocated']:.1f}GB\")\n",
        "        print(f\"  Utilization: {stats['utilization']:.1f}%\")\n",
        "\n",
        "print(\"\\nüéâ Ukrainian OCR Pipeline processing complete!\")\n",
        "print(\"üìö Check the downloaded archive for all your results.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "next-steps"
      },
      "source": [
        "## üöÄ Next Steps\n",
        "\n",
        "**What you can do with the results:**\n",
        "\n",
        "1. **ALTO XML files** - Import into eScriptorium or other document analysis tools\n",
        "2. **Enhanced ALTO** - Contains named entity annotations for persons and locations\n",
        "3. **Person-dense regions** - Cropped images focusing on genealogically valuable content\n",
        "4. **Entity extraction** - Use the identified persons and locations for genealogical research\n",
        "\n",
        "**For production use:**\n",
        "- Install locally: `pip install ukrainian-ocr-pipeline[all]`\n",
        "- Use CLI interface: `ukrainian-ocr --help`\n",
        "- Customize configuration files\n",
        "- Integrate with existing workflows\n",
        "\n",
        "**Need help?**\n",
        "- üìñ Documentation: [Link to docs]\n",
        "- üêõ Issues: [Link to GitHub issues]\n",
        "- üí¨ Discussions: [Link to discussions]\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}