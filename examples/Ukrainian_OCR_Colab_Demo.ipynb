{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# 🇺🇦 Ukrainian OCR Pipeline - Google Colab Demo\n\nThis notebook demonstrates the **Ukrainian OCR Pipeline Package** in Google Colab.\n\n## Quick Start:\n1. **Upload your document** using the file uploader\n2. **Run all cells** for complete processing  \n3. **Download results** at the end\n\n**Two-Stage Processing**: Segmentation → Recognition & Enhancement"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": "## 🔧 Setup & Installation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# Clone repository and install package\nprint(\"📥 Cloning Ukrainian OCR repository...\")\n!git clone https://github.com/mary-lev/ukrainian-ocr-package.git /content/ukrainian_ocr_package\n\nprint(\"⚙️ Installing Ukrainian OCR package...\")\n!cd /content/ukrainian_ocr_package && pip install -e .\n\nprint(\"✅ Installation complete!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": "## 📦 Import Libraries"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport sys\nimport time\nfrom pathlib import Path\n\n# Add package to path\nsys.path.insert(0, '/content/ukrainian_ocr_package')\n\n# Core libraries\nimport torch\nimport numpy as np\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Ukrainian OCR Package\nfrom ukrainian_ocr import UkrainianOCRPipeline\nfrom ukrainian_ocr.core.config import OCRPipelineConfig\n\n# Colab utilities\nfrom google.colab import files\n\nprint(\"✅ All libraries loaded successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# Create default configuration\nconfig = OCRPipelineConfig()\nconfig.update_for_colab()\n\nprint(f\"✅ Configuration ready\")\nprint(f\"🎯 Device: {config.device}\")\nprint(f\"📦 Batch size: {config.batch_size}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": "## 📤 Upload Document"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "print(\"📤 Upload your Ukrainian document (JPG, PNG, TIFF):\")\nuploaded = files.upload()\n\nif uploaded:\n    test_image_path = list(uploaded.keys())[0]\n    print(f\"✅ Document uploaded: {test_image_path}\")\n    \n    # Display document preview\n    with Image.open(test_image_path) as img:\n        print(f\"📐 Dimensions: {img.size[0]} x {img.size[1]} pixels\")\n        plt.figure(figsize=(10, 6))\n        plt.imshow(img)\n        plt.title(f\"Document: {test_image_path}\")\n        plt.axis('off')\n        plt.show()\nelse:\n    print(\"❌ No file uploaded\")\n    test_image_path = None"
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": "## 🏁 Stage 1: Document Segmentation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "if not test_image_path:\n    print(\"❌ Please upload a document first\")\nelse:\n    print(\"🚀 Starting segmentation...\")\n    \n    # Initialize pipeline\n    pipeline = UkrainianOCRPipeline(config=config)\n    output_dir = Path(\"/content/ukrainian_ocr_output\")\n    output_dir.mkdir(exist_ok=True)\n    \n    # Load and segment image\n    start_time = time.time()\n    pipeline._init_components()\n    image = cv2.imread(test_image_path)\n    lines = pipeline.segmenter.segment_image(image)\n    seg_time = time.time() - start_time\n    \n    print(f\"✅ Segmentation complete: {seg_time:.2f}s\")\n    print(f\"📊 Detected {len(lines)} text lines\")\n    \n    # Create basic ALTO XML\n    basic_alto_xml = pipeline._create_alto_xml(Path(test_image_path), image, lines)\n    basic_alto_path = output_dir / f\"{Path(test_image_path).stem}_basic_alto.xml\"\n    with open(basic_alto_path, 'w', encoding='utf-8') as f:\n        f.write(basic_alto_xml)\n    \n    print(f\"✅ Basic ALTO created: {basic_alto_path}\")\n    \n    # Create visualization\n    vis_image = image.copy()\n    colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0)]\n    \n    for idx, line in enumerate(lines[:100]):  # Show first 100 lines\n        color = colors[idx % len(colors)]\n        polygon = line.get('polygon', [])\n        if polygon and len(polygon) >= 3:\n            pts = np.array(polygon, np.int32)\n            cv2.polylines(vis_image, [pts], True, color, 2)\n    \n    plt.figure(figsize=(12, 8))\n    plt.imshow(cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB))\n    plt.title(f\"Segmentation: {len(lines)} lines detected\")\n    plt.axis('off')\n    plt.show()\n    \n    # Store for next stage\n    stage1_results = {\n        'image': image,\n        'lines': lines,\n        'segmentation_time': seg_time,\n        'output_dir': output_dir\n    }"
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": "## 🤖 Stage 2: Text Recognition & Enhancement"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "if 'stage1_results' not in locals():\n    print(\"❌ Please run Stage 1 first\")\nelse:\n    print(\"🚀 Starting text recognition & enhancement...\")\n    \n    image = stage1_results['image']\n    lines = stage1_results['lines']\n    output_dir = stage1_results['output_dir']\n    \n    # Text Recognition\n    print(f\"🤖 Processing {len(lines)} lines...\")\n    start_time = time.time()\n    lines_with_text = pipeline.ocr_processor.process_lines(image, lines)\n    ocr_time = time.time() - start_time\n    \n    recognized_lines = [l for l in lines_with_text if l.get('text', '').strip()]\n    print(f\"✅ OCR complete: {ocr_time:.2f}s\")\n    print(f\"📊 Text in {len(recognized_lines)}/{len(lines)} lines\")\n    \n    # Show sample text\n    print(\"\\n📝 Sample recognized text:\")\n    for i, line in enumerate(recognized_lines[:5]):\n        text = line.get('text', '')\n        print(f\"  {i+1}. '{text}'\")\n    \n    # Named Entity Recognition\n    print(\"\\n🏷️ Named Entity Recognition...\")\n    start_time = time.time()\n    ner_results = pipeline.ner_extractor.extract_entities_from_lines(lines_with_text)\n    ner_time = time.time() - start_time\n    \n    all_entities = ner_results.get('all_entities', [])\n    print(f\"✅ NER complete: {ner_time:.2f}s\")\n    print(f\"🏷️ Found {len(all_entities)} entities\")\n    \n    if all_entities:\n        print(\"\\nSample entities:\")\n        for entity in all_entities[:5]:\n            print(f\"  '{entity.get('text', '')}' -> {entity.get('label', '')}\")\n    \n    # Surname Matching\n    print(\"\\n👥 Surname Matching...\")\n    start_time = time.time()\n    surname_matches = pipeline.surname_matcher.find_in_lines(lines_with_text)\n    surname_time = time.time() - start_time\n    \n    print(f\"✅ Surname matching: {surname_time:.2f}s\")\n    print(f\"👥 Found {len(surname_matches)} matches\")\n    \n    if surname_matches:\n        print(\"\\nSample matches:\")\n        for match in surname_matches[:5]:\n            print(f\"  '{match.found_text}' -> '{match.matched_surname}' ({match.confidence:.2f})\")\n        \n        # Export matches\n        matches_file = output_dir / f\"{Path(test_image_path).stem}_surnames.json\"\n        pipeline.surname_matcher.export_matches(surname_matches, str(matches_file))\n    \n    # Create Complete ALTO\n    print(\"\\n✨ Creating enhanced ALTO...\")\n    complete_alto_xml = pipeline._create_alto_xml(Path(test_image_path), image, lines_with_text)\n    complete_alto_path = output_dir / f\"{Path(test_image_path).stem}_complete_alto.xml\"\n    with open(complete_alto_path, 'w', encoding='utf-8') as f:\n        f.write(complete_alto_xml)\n    \n    # Enhanced ALTO with NER (if entities found)\n    if all_entities:\n        entities_by_line_id = {}\n        for idx, line in enumerate(lines_with_text):\n            line_id = f\"line_{idx}\"\n            line_text = line.get('text', '')\n            line_entities = [e for e in all_entities if e.get('text', '') in line_text]\n            if line_entities:\n                entities_by_line_id[line_id] = {'entities': line_entities}\n        \n        if entities_by_line_id:\n            enhanced_alto_path = output_dir / f\"{Path(test_image_path).stem}_enhanced_alto.xml\"\n            pipeline.alto_enhancer.enhance_alto_with_ner(\n                str(complete_alto_path), entities_by_line_id, str(enhanced_alto_path)\n            )\n    \n    # Summary\n    total_time = stage1_results['segmentation_time'] + ocr_time + ner_time + surname_time\n    print(f\"\\n📊 PROCESSING COMPLETE\")\n    print(f\"⏱️ Total time: {total_time:.2f}s\")\n    print(f\"🔍 Lines detected: {len(lines)}\")\n    print(f\"📝 Lines with text: {len(recognized_lines)}\")\n    print(f\"🏷️ Entities found: {len(all_entities)}\")\n    print(f\"👥 Surname matches: {len(surname_matches)}\")\n    \n    # Store for download\n    processing_results = {\n        'output_dir': output_dir,\n        'total_time': total_time\n    }"
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": "## 📥 Download Results"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": "if 'processing_results' in locals():\n    print(\"📥 Downloading your OCR results...\")\n    \n    output_dir = processing_results['output_dir']\n    \n    # Create a zip file with all results\n    import zipfile\n    zip_path = \"/content/ukrainian_ocr_results.zip\"\n    \n    with zipfile.ZipFile(zip_path, 'w') as zipf:\n        for file_path in output_dir.glob(\"*\"):\n            zipf.write(file_path, file_path.name)\n    \n    print(f\"📦 Created results archive\")\n    \n    # List generated files\n    print(\"\\n📁 Generated files:\")\n    for file_path in output_dir.glob(\"*\"):\n        size_kb = file_path.stat().st_size / 1024\n        print(f\"  📄 {file_path.name} ({size_kb:.1f} KB)\")\n    \n    # Download the zip file\n    files.download(zip_path)\n    print(\"\\n✅ Download started!\")\n    \nelse:\n    print(\"❌ No processing results found. Please run the processing cells first.\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": "## 📋 Results Summary\n\n### Generated Files:\n- **Basic ALTO XML**: Segmentation with coordinates\n- **Complete ALTO XML**: Full transcription with confidence scores  \n- **Enhanced ALTO XML**: With NER semantic annotations (if entities found)\n- **Surname Matches JSON**: Genealogical findings with fuzzy matching\n- **Segmentation PNG**: Visual representation of detected text lines\n\n### Usage:\n- Import ALTO files into eScriptorium or XML editors\n- Analyze surname matches for genealogical research\n- Process additional documents by re-running the notebook\n\n---\n**🇺🇦 Ukrainian OCR Pipeline** - [GitHub Repository](https://github.com/mary-lev/ukrainian-ocr-package)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}