{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# üá∫üá¶ Ukrainian OCR Pipeline - Google Colab Demo\n",
    "\n",
    "This notebook demonstrates the **Ukrainian OCR Pipeline Package** in Google Colab environment.\n",
    "\n",
    "## Features:\n",
    "- **Automatic GPU Detection** and optimization for Colab T4/V100/A100\n",
    "- **GitHub Integration** with automatic repository cloning\n",
    "- **Two-Stage Processing**: Segmentation ‚Üí Recognition & Enhancement\n",
    "- **Complete Pipeline**: Kraken ‚Üí TrOCR ‚Üí NER ‚Üí Surname Matching ‚Üí Enhanced ALTO\n",
    "- **Download Support**: Results automatically downloadable from Colab\n",
    "\n",
    "## Quick Start:\n",
    "1. **Upload your document** using the file uploader\n",
    "2. **Run all cells** for complete processing\n",
    "3. **Download results** from the generated files section\n",
    "\n",
    "---\n",
    "**‚ö° Optimized for Google Colab Free/Pro/Pro+ GPUs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## üîß Environment Setup & Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're in Google Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üöÄ Running in Google Colab\")\n",
    "    \n",
    "    # Mount Google Drive (optional)\n",
    "    from google.colab import drive\n",
    "    try:\n",
    "        drive.mount('/content/drive')\n",
    "        print(\"‚úÖ Google Drive mounted\")\n",
    "    except:\n",
    "        print(\"‚ö†Ô∏è Google Drive mount failed (optional)\")\n",
    "    \n",
    "    # Install system dependencies\n",
    "    print(\"üì¶ Installing system dependencies...\")\n",
    "    !apt-get update -qq\n",
    "    !apt-get install -y -qq libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1\n",
    "    \n",
    "    # Clone the repository\n",
    "    print(\"üì• Cloning Ukrainian OCR repository...\")\n",
    "    !git clone https://github.com/your-repo/ukrainian-ocr-package.git /content/ukrainian_ocr_package\n",
    "    \n",
    "    # Install the package\n",
    "    print(\"‚öôÔ∏è Installing Ukrainian OCR package...\")\n",
    "    !cd /content/ukrainian_ocr_package && pip install -e .\n",
    "    \n",
    "    print(\"‚úÖ Installation complete!\")\n",
    "else:\n",
    "    print(\"üíª Running in local environment\")\n",
    "    print(\"‚ö†Ô∏è This notebook is optimized for Google Colab\")\n",
    "    print(\"üìù For local development, use Ukrainian_OCR_Local_Demo.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## üì¶ Package Import & Hardware Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Core libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Ukrainian OCR Package\n",
    "if IN_COLAB:\n",
    "    sys.path.insert(0, '/content/ukrainian_ocr_package')\n",
    "\n",
    "from ukrainian_ocr import UkrainianOCRPipeline\n",
    "from ukrainian_ocr.core.config import OCRPipelineConfig\n",
    "\n",
    "print(f\"‚úÖ Ukrainian OCR Package loaded\")\n",
    "print(f\"üìç Package location: {__import__('ukrainian_ocr').__file__}\")\n",
    "\n",
    "# Google Colab specific imports\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üñ•Ô∏è Hardware Detection:\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# GPU detection optimized for Colab\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"‚úÖ GPU: {gpu_name} ({gpu_memory:.1f}GB VRAM)\")\n",
    "    \n",
    "    # Optimize for different Colab GPU types\n",
    "    if 'T4' in gpu_name:\n",
    "        device = 'cuda'\n",
    "        batch_size = 4  # Conservative for T4\n",
    "        print(\"üéØ Optimized for Colab T4 GPU\")\n",
    "    elif 'V100' in gpu_name or 'A100' in gpu_name:\n",
    "        device = 'cuda'\n",
    "        batch_size = 8  # More aggressive for Pro/Pro+\n",
    "        print(\"üéØ Optimized for Colab Pro/Pro+ GPU\")\n",
    "    else:\n",
    "        device = 'cuda'\n",
    "        batch_size = 6  # Default for other GPUs\n",
    "        print(\"üéØ Optimized for GPU\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GPU not available - using CPU (will be slower)\")\n",
    "    device = 'cpu'\n",
    "    batch_size = 1\n",
    "\n",
    "print(f\"üéØ Selected device: {device}\")\n",
    "print(f\"üì¶ Batch size: {batch_size}\")\n",
    "\n",
    "# Create Colab-optimized configuration\n",
    "config = {\n",
    "    'device': device,\n",
    "    'batch_size': batch_size,\n",
    "    'verbose': True,\n",
    "    'save_intermediate': True,\n",
    "    \n",
    "    'ocr': {\n",
    "        'model_path': 'cyrillic-trocr/trocr-handwritten-cyrillic',\n",
    "        'device': device,\n",
    "        'batch_size': batch_size\n",
    "    },\n",
    "    \n",
    "    'ner': {\n",
    "        'backend': 'spacy',  # Most stable for Colab\n",
    "        'device': device,\n",
    "        'confidence_threshold': 0.7\n",
    "    },\n",
    "    \n",
    "    'surname_matching': {\n",
    "        'enabled': True,\n",
    "        'threshold': 0.8,\n",
    "        'use_phonetic': True,\n",
    "        'export_matches': True,\n",
    "        'surnames': [\n",
    "            '–®–µ–≤—á–µ–Ω–∫–æ', '–ö–æ–≤–∞–ª–µ–Ω–∫–æ', '–ë–æ–Ω–¥–∞—Ä–µ–Ω–∫–æ', '–¢–∫–∞—á–µ–Ω–∫–æ', '–ö—Ä–∞–≤—á–µ–Ω–∫–æ',\n",
    "            '–ü–µ—Ç—Ä–µ–Ω–∫–æ', '–Ü–≤–∞–Ω–µ–Ω–∫–æ', '–ú–∏—Ö–∞–π–ª–µ–Ω–∫–æ', '–í–∞—Å–∏–ª–µ–Ω–∫–æ', '–ì—Ä–∏–≥–æ—Ä–µ–Ω–∫–æ',\n",
    "            '–ö–æ–≤–∞–ª—å—á—É–∫', '–°–∞–≤—á–µ–Ω–∫–æ', '–õ–µ–≤—á–µ–Ω–∫–æ', '–ü–∞–≤–ª–µ–Ω–∫–æ', '–ú–∞—Ä—á–µ–Ω–∫–æ',\n",
    "            '–ú–µ–ª—å–Ω–∏–∫', '–ö–æ–≤–∞–ª—å', '–ì–æ–Ω—á–∞—Ä', '–ö—Ä–∞–≤–µ—Ü—å', '–®–≤–µ—Ü—å',\n",
    "            '–ñ—É–∫', '–ö–æ–∑–ª–æ–≤', '–ú–æ—Ä–æ–∑', '–¢–µ—Ä–µ—â–µ–Ω–∫–æ', '–†–∏–±–∞–ª–∫–æ'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'post_processing': {\n",
    "        'extract_person_regions': True,\n",
    "        'clustering_eps': 300\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration optimized for Google Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## üì§ Upload Document for Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    print(\"üì§ Upload your Ukrainian document (JPG, PNG, TIFF):\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    if uploaded:\n",
    "        # Get the uploaded file\n",
    "        test_image_path = list(uploaded.keys())[0]\n",
    "        print(f\"‚úÖ Document uploaded: {test_image_path}\")\n",
    "        \n",
    "        # Move to content directory for easier access\n",
    "        import shutil\n",
    "        dest_path = f\"/content/{test_image_path}\"\n",
    "        if os.path.exists(test_image_path) and test_image_path != dest_path:\n",
    "            shutil.move(test_image_path, dest_path)\n",
    "            test_image_path = dest_path\n",
    "    else:\n",
    "        print(\"‚ùå No file uploaded\")\n",
    "        test_image_path = None\n",
    "else:\n",
    "    # For local testing\n",
    "    test_image_paths = [\n",
    "        \"./sample_document.jpg\",\n",
    "        \"../test_images/ukrainian_document.jpg\"\n",
    "    ]\n",
    "    \n",
    "    test_image_path = None\n",
    "    for path in test_image_paths:\n",
    "        if os.path.exists(path):\n",
    "            test_image_path = path\n",
    "            break\n",
    "\n",
    "if test_image_path and os.path.exists(test_image_path):\n",
    "    # Display document information\n",
    "    image_size = os.path.getsize(test_image_path) / (1024 * 1024)\n",
    "    \n",
    "    with Image.open(test_image_path) as img:\n",
    "        width, height = img.size\n",
    "        \n",
    "        print(f\"üìÑ Document: {os.path.basename(test_image_path)}\")\n",
    "        print(f\"üìä Size: {image_size:.1f} MB\")\n",
    "        print(f\"üìê Dimensions: {width} x {height} pixels\")\n",
    "        print(f\"üìù Format: {img.format}\")\n",
    "        \n",
    "        # Display preview\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Document: {os.path.basename(test_image_path)}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No document available for processing\")\n",
    "    if IN_COLAB:\n",
    "        print(\"Please run the upload cell above\")\n",
    "    else:\n",
    "        print(\"Please add a document to the test_image_paths list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## üèÅ Stage 1: Document Segmentation & Basic ALTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not test_image_path or not os.path.exists(test_image_path):\n",
    "    print(\"‚ùå Cannot proceed without a document. Please upload a file.\")\n",
    "else:\n",
    "    print(\"üöÄ STAGE 1: Document Segmentation & Basic ALTO Creation\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    pipeline_config = OCRPipelineConfig.from_dict(config)\n",
    "    \n",
    "    # Update for Colab environment\n",
    "    pipeline_config.update_for_colab()\n",
    "    \n",
    "    pipeline = UkrainianOCRPipeline(config=pipeline_config)\n",
    "    \n",
    "    print(f\"‚úÖ Pipeline ready (device: {pipeline.device})\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(\"/content/ukrainian_ocr_output\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Load and process image\n",
    "    print(\"\\nüîç Kraken Segmentation...\")\n",
    "    if device == 'cpu':\n",
    "        print(\"‚è≥ CPU processing detected - this may take a few minutes\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize components\n",
    "    pipeline._init_components()\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(test_image_path)\n",
    "    \n",
    "    # Segment image\n",
    "    lines = pipeline.segmenter.segment_image(image)\n",
    "    seg_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚úÖ Segmentation complete: {seg_time:.2f}s\")\n",
    "    print(f\"üìä Detected {len(lines)} text lines\")\n",
    "    \n",
    "    # Create basic ALTO XML\n",
    "    print(\"\\nüìÑ Creating basic ALTO XML...\")\n",
    "    basic_alto_xml = pipeline._create_alto_xml(Path(test_image_path), image, lines)\n",
    "    \n",
    "    basic_alto_path = output_dir / f\"{Path(test_image_path).stem}_basic_alto.xml\"\n",
    "    with open(basic_alto_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(basic_alto_xml)\n",
    "    \n",
    "    print(f\"‚úÖ Basic ALTO created: {basic_alto_path}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    print(\"\\nüé® Creating segmentation visualization...\")\n",
    "    vis_image = image.copy()\n",
    "    colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0)]\n",
    "    \n",
    "    for idx, line in enumerate(lines[:200]):  # Show first 200 lines to avoid clutter\n",
    "        color = colors[idx % len(colors)]\n",
    "        polygon = line.get('polygon', [])\n",
    "        if polygon and len(polygon) >= 3:\n",
    "            pts = np.array(polygon, np.int32)\n",
    "            cv2.polylines(vis_image, [pts], True, color, 2)\n",
    "    \n",
    "    # Save and display visualization\n",
    "    vis_path = output_dir / f\"{Path(test_image_path).stem}_segmentation.png\"\n",
    "    cv2.imwrite(str(vis_path), vis_image)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Segmentation: {len(lines)} lines detected\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Stage 1 complete - ready for text recognition\")\n",
    "    \n",
    "    # Store results for Stage 2\n",
    "    stage1_results = {\n",
    "        'image': image,\n",
    "        'lines': lines,\n",
    "        'segmentation_time': seg_time,\n",
    "        'basic_alto_path': basic_alto_path,\n",
    "        'output_dir': output_dir\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## ü§ñ Stage 2: Text Recognition, NER & Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'stage1_results' not in locals():\n",
    "    print(\"‚ùå Please run Stage 1 first\")\n",
    "else:\n",
    "    print(\"üöÄ STAGE 2: Text Recognition, NER & Enhancement\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    image = stage1_results['image']\n",
    "    lines = stage1_results['lines']\n",
    "    output_dir = stage1_results['output_dir']\n",
    "    \n",
    "    print(f\"üìÑ Processing {len(lines)} lines\")\n",
    "    \n",
    "    # Text Recognition with TrOCR\n",
    "    print(\"\\nü§ñ TrOCR Text Recognition...\")\n",
    "    if device == 'cpu':\n",
    "        print(\"‚è≥ CPU processing - this will take several minutes\")\n",
    "    elif 'T4' in torch.cuda.get_device_name(0):\n",
    "        print(\"‚ö° T4 GPU detected - optimized processing\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    lines_with_text = pipeline.ocr_processor.process_lines(image, lines)\n",
    "    ocr_time = time.time() - start_time\n",
    "    \n",
    "    recognized_lines = [l for l in lines_with_text if l.get('text', '').strip()]\n",
    "    print(f\"‚úÖ OCR complete: {ocr_time:.2f}s\")\n",
    "    print(f\"üìä Text in {len(recognized_lines)}/{len(lines)} lines\")\n",
    "    \n",
    "    # Show sample text\n",
    "    print(\"\\nüìù Sample recognized text:\")\n",
    "    for i, line in enumerate(recognized_lines[:8]):\n",
    "        text = line.get('text', '')\n",
    "        conf = line.get('confidence', 0)\n",
    "        print(f\"  {i+1}. '{text}' ({conf:.2f})\")\n",
    "    \n",
    "    # Named Entity Recognition\n",
    "    print(\"\\nüè∑Ô∏è Named Entity Recognition...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ner_results = pipeline.ner_extractor.extract_entities_from_lines(lines_with_text)\n",
    "    ner_time = time.time() - start_time\n",
    "    \n",
    "    all_entities = ner_results.get('all_entities', [])\n",
    "    print(f\"‚úÖ NER complete: {ner_time:.2f}s\")\n",
    "    print(f\"üè∑Ô∏è Found {len(all_entities)} entities\")\n",
    "    print(f\"üß† Backend: {ner_results.get('backend', 'unknown')}\")\n",
    "    \n",
    "    if all_entities:\n",
    "        # Group by type\n",
    "        entity_types = {}\n",
    "        for entity in all_entities:\n",
    "            label = entity.get('label', 'UNKNOWN')\n",
    "            entity_types[label] = entity_types.get(label, 0) + 1\n",
    "        \n",
    "        print(\"\\nEntity types:\")\n",
    "        for etype, count in entity_types.items():\n",
    "            print(f\"  {etype}: {count}\")\n",
    "        \n",
    "        print(\"\\nSample entities:\")\n",
    "        for entity in all_entities[:8]:\n",
    "            print(f\"  '{entity.get('text', '')}' -> {entity.get('label', '')}\")\n",
    "    \n",
    "    # Surname Matching\n",
    "    print(\"\\nüë• Surname Matching...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    surname_matches = pipeline.surname_matcher.find_in_lines(lines_with_text)\n",
    "    surname_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚úÖ Surname matching: {surname_time:.2f}s\")\n",
    "    print(f\"üë• Found {len(surname_matches)} matches\")\n",
    "    \n",
    "    if surname_matches:\n",
    "        unique_surnames = set(m.matched_surname for m in surname_matches)\n",
    "        print(f\"üìä Unique surnames: {len(unique_surnames)}\")\n",
    "        \n",
    "        print(\"\\nSample matches:\")\n",
    "        for match in surname_matches[:8]:\n",
    "            print(f\"  '{match.found_text}' -> '{match.matched_surname}' ({match.confidence:.2f})\")\n",
    "        \n",
    "        # Export matches\n",
    "        matches_file = output_dir / f\"{Path(test_image_path).stem}_surnames.json\"\n",
    "        pipeline.surname_matcher.export_matches(surname_matches, str(matches_file))\n",
    "        print(f\"üíæ Surnames saved: {matches_file}\")\n",
    "    \n",
    "    # Create Enhanced ALTO\n",
    "    print(\"\\n‚ú® Creating Enhanced ALTO...\")\n",
    "    \n",
    "    # Complete ALTO with text\n",
    "    complete_alto_xml = pipeline._create_alto_xml(Path(test_image_path), image, lines_with_text)\n",
    "    complete_alto_path = output_dir / f\"{Path(test_image_path).stem}_complete_alto.xml\"\n",
    "    \n",
    "    with open(complete_alto_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(complete_alto_xml)\n",
    "    \n",
    "    print(f\"‚úÖ Complete ALTO: {complete_alto_path}\")\n",
    "    \n",
    "    # Enhanced ALTO with NER (if entities found)\n",
    "    enhanced_alto_path = None\n",
    "    if all_entities:\n",
    "        # Map entities to lines\n",
    "        entities_by_line_id = {}\n",
    "        for idx, line in enumerate(lines_with_text):\n",
    "            line_id = f\"line_{idx}\"\n",
    "            line_text = line.get('text', '')\n",
    "            \n",
    "            line_entities = []\n",
    "            for entity in all_entities:\n",
    "                if entity.get('text', '') in line_text:\n",
    "                    line_entities.append(entity)\n",
    "            \n",
    "            if line_entities:\n",
    "                entities_by_line_id[line_id] = {'entities': line_entities}\n",
    "        \n",
    "        if entities_by_line_id:\n",
    "            enhanced_alto_path = output_dir / f\"{Path(test_image_path).stem}_enhanced_alto.xml\"\n",
    "            pipeline.alto_enhancer.enhance_alto_with_ner(\n",
    "                str(complete_alto_path), entities_by_line_id, str(enhanced_alto_path)\n",
    "            )\n",
    "            print(f\"‚úÖ Enhanced ALTO: {enhanced_alto_path}\")\n",
    "    \n",
    "    # Final Summary\n",
    "    total_time = stage1_results['segmentation_time'] + ocr_time + ner_time + surname_time\n",
    "    \n",
    "    print(\"\\nüìä PROCESSING COMPLETE\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"‚è±Ô∏è Total time: {total_time:.2f}s\")\n",
    "    print(f\"üîç Lines detected: {len(lines)}\")\n",
    "    print(f\"üìù Lines with text: {len(recognized_lines)}\")\n",
    "    print(f\"üè∑Ô∏è Entities found: {len(all_entities)}\")\n",
    "    print(f\"üë• Surname matches: {len(surname_matches)}\")\n",
    "    \n",
    "    # List output files\n",
    "    print(\"\\nüìÅ Generated files:\")\n",
    "    generated_files = []\n",
    "    for file_path in output_dir.glob(\"*\"):\n",
    "        size_kb = file_path.stat().st_size / 1024\n",
    "        print(f\"  üìÑ {file_path.name} ({size_kb:.1f} KB)\")\n",
    "        generated_files.append(str(file_path))\n",
    "    \n",
    "    print(f\"\\n‚úÖ All files saved in: {output_dir}\")\n",
    "    print(\"üéâ Ukrainian OCR processing completed!\")\n",
    "    \n",
    "    # Store for download section\n",
    "    processing_results = {\n",
    "        'output_dir': output_dir,\n",
    "        'generated_files': generated_files,\n",
    "        'total_time': total_time,\n",
    "        'stats': {\n",
    "            'lines_detected': len(lines),\n",
    "            'lines_with_text': len(recognized_lines),\n",
    "            'entities_found': len(all_entities),\n",
    "            'surname_matches': len(surname_matches)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## üì• Download Results (Colab Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB and 'processing_results' in locals():\n",
    "    print(\"üì• Download your OCR results:\")\n",
    "    \n",
    "    output_dir = processing_results['output_dir']\n",
    "    \n",
    "    # Create a zip file with all results\n",
    "    import zipfile\n",
    "    zip_path = \"/content/ukrainian_ocr_results.zip\"\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        for file_path in output_dir.glob(\"*\"):\n",
    "            zipf.write(file_path, file_path.name)\n",
    "    \n",
    "    print(f\"üì¶ Created results archive: {zip_path}\")\n",
    "    \n",
    "    # Download the zip file\n",
    "    files.download(zip_path)\n",
    "    \n",
    "    # Also offer individual file downloads\n",
    "    print(\"\\nüìÑ Or download individual files:\")\n",
    "    \n",
    "    # Create download buttons for each file\n",
    "    for file_path in sorted(output_dir.glob(\"*\")):\n",
    "        file_size = file_path.stat().st_size / 1024\n",
    "        print(f\"\\nüìÑ {file_path.name} ({file_size:.1f} KB)\")\n",
    "        \n",
    "        # Create download button\n",
    "        display(HTML(f'''\n",
    "        <button onclick=\"window.open('/files/{file_path}', '_blank')\">\n",
    "            Download {file_path.name}\n",
    "        </button>\n",
    "        '''))\n",
    "    \n",
    "    print(\"\\n‚úÖ All files are ready for download!\")\n",
    "    \n",
    "elif IN_COLAB:\n",
    "    print(\"‚ùå No processing results found. Please run the processing cells first.\")\n",
    "else:\n",
    "    print(\"üíª Running locally - files are saved to the output directory\")\n",
    "    if 'processing_results' in locals():\n",
    "        print(f\"üìÅ Results saved in: {processing_results['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## üìã Results Summary & Usage Tips\n",
    "\n",
    "### Generated Files:\n",
    "- **Basic ALTO XML**: Segmentation with coordinates only\n",
    "- **Complete ALTO XML**: Full transcription with confidence scores  \n",
    "- **Enhanced ALTO XML**: With NER semantic annotations (if entities found)\n",
    "- **Surname Matches JSON**: Genealogical findings with fuzzy matching\n",
    "- **Segmentation PNG**: Visual representation of detected text lines\n",
    "\n",
    "### Google Colab Tips:\n",
    "1. **GPU Usage**: This notebook automatically detects and optimizes for T4/V100/A100 GPUs\n",
    "2. **Runtime Management**: Long processing may timeout - save intermediate results\n",
    "3. **File Persistence**: Files are saved in `/content/` and will be lost when runtime disconnects\n",
    "4. **Memory Management**: Large documents may require Pro/Pro+ for sufficient RAM\n",
    "\n",
    "### Next Steps:\n",
    "1. **Review ALTO files** in XML editor or import into eScriptorium\n",
    "2. **Analyze surname matches** for genealogical research projects\n",
    "3. **Process multiple documents** by re-running with different uploads\n",
    "4. **Customize surname lists** by modifying the configuration above\n",
    "5. **Adjust confidence thresholds** for better precision/recall balance\n",
    "\n",
    "### Performance Optimization:\n",
    "- **Batch Processing**: Upload multiple documents and process in sequence\n",
    "- **Model Caching**: Models are cached between runs in the same session\n",
    "- **GPU Memory**: Restart runtime if you encounter CUDA out-of-memory errors\n",
    "- **Image Size**: Very large images may need resizing for optimal processing\n",
    "\n",
    "---\n",
    "**üá∫üá¶ Ukrainian OCR Pipeline** - Optimized for Google Colab environments\n",
    "\n",
    "**üîó Repository**: [GitHub Repository Link]\n",
    "\n",
    "**üìö Documentation**: [Package Documentation Link]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}