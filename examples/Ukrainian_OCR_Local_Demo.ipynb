{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ‡ºğŸ‡¦ Ukrainian OCR Pipeline - Local Environment Demo\n",
    "\n",
    "This notebook demonstrates the **Ukrainian OCR Pipeline Package** in a local development environment.\n",
    "\n",
    "## Features:\n",
    "- **GPU/CPU Auto-detection** with performance optimization\n",
    "- **Two-Stage Processing**: Segmentation â†’ Recognition & Enhancement\n",
    "- **Complete Pipeline**: Kraken â†’ TrOCR â†’ NER â†’ Surname Matching â†’ Enhanced ALTO\n",
    "- **Professional Output**: ALTO XML v4, visualizations, and detailed reports\n",
    "\n",
    "## Requirements:\n",
    "- Ukrainian OCR package installed (`pip install -e .` from package directory)\n",
    "- Document image in supported format (JPG, PNG, TIFF)\n",
    "- Python 3.8+ with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Package Import & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Core libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add package to path if running from examples directory\n",
    "if os.path.exists('../ukrainian_ocr'):\n",
    "    sys.path.insert(0, '..')\n",
    "    print(\"âœ… Using local development version\")\n",
    "\n",
    "# Import Ukrainian OCR Package\n",
    "from ukrainian_ocr import UkrainianOCRPipeline\n",
    "from ukrainian_ocr.core.config import OCRPipelineConfig\n",
    "\n",
    "print(f\"âœ… Ukrainian OCR Package loaded\")\n",
    "print(f\"ğŸ“ Package location: {__import__('ukrainian_ocr').__file__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ–¥ï¸ Hardware Detection & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ–¥ï¸ Hardware Detection:\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# GPU detection and optimization\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"âœ… GPU: {gpu_name} ({gpu_memory:.1f}GB VRAM)\")\n",
    "    device = 'cuda'\n",
    "    batch_size = 8 if gpu_memory > 12 else 4  # Optimize batch size for local GPU\n",
    "else:\n",
    "    print(\"âš ï¸ GPU not available - using CPU\")\n",
    "    device = 'cpu'\n",
    "    batch_size = 1\n",
    "\n",
    "print(f\"ğŸ¯ Selected device: {device}\")\n",
    "print(f\"ğŸ“¦ Batch size: {batch_size}\")\n",
    "\n",
    "# Create optimized configuration for local environment\n",
    "config = {\n",
    "    'device': device,\n",
    "    'batch_size': batch_size,\n",
    "    'verbose': True,\n",
    "    'save_intermediate': True,  # Save all intermediate files locally\n",
    "    \n",
    "    'ocr': {\n",
    "        'model_path': 'cyrillic-trocr/trocr-handwritten-cyrillic',\n",
    "        'device': device,\n",
    "        'batch_size': batch_size\n",
    "    },\n",
    "    \n",
    "    'ner': {\n",
    "        'backend': 'transformers',  # Best quality for local processing\n",
    "        'device': device,\n",
    "        'confidence_threshold': 0.7\n",
    "    },\n",
    "    \n",
    "    'surname_matching': {\n",
    "        'enabled': True,\n",
    "        'threshold': 0.8,\n",
    "        'use_phonetic': True,\n",
    "        'export_matches': True,\n",
    "        'surnames': [\n",
    "            'Ğ¨ĞµĞ²Ñ‡ĞµĞ½ĞºĞ¾', 'ĞšĞ¾Ğ²Ğ°Ğ»ĞµĞ½ĞºĞ¾', 'Ğ‘Ğ¾Ğ½Ğ´Ğ°Ñ€ĞµĞ½ĞºĞ¾', 'Ğ¢ĞºĞ°Ñ‡ĞµĞ½ĞºĞ¾', 'ĞšÑ€Ğ°Ğ²Ñ‡ĞµĞ½ĞºĞ¾',\n",
    "            'ĞŸĞµÑ‚Ñ€ĞµĞ½ĞºĞ¾', 'Ğ†Ğ²Ğ°Ğ½ĞµĞ½ĞºĞ¾', 'ĞœĞ¸Ñ…Ğ°Ğ¹Ğ»ĞµĞ½ĞºĞ¾', 'Ğ’Ğ°ÑĞ¸Ğ»ĞµĞ½ĞºĞ¾', 'Ğ“Ñ€Ğ¸Ğ³Ğ¾Ñ€ĞµĞ½ĞºĞ¾',\n",
    "            'ĞšĞ¾Ğ²Ğ°Ğ»ÑŒÑ‡ÑƒĞº', 'Ğ¡Ğ°Ğ²Ñ‡ĞµĞ½ĞºĞ¾', 'Ğ›ĞµĞ²Ñ‡ĞµĞ½ĞºĞ¾', 'ĞŸĞ°Ğ²Ğ»ĞµĞ½ĞºĞ¾', 'ĞœĞ°Ñ€Ñ‡ĞµĞ½ĞºĞ¾',\n",
    "            'ĞœĞµĞ»ÑŒĞ½Ğ¸Ğº', 'ĞšĞ¾Ğ²Ğ°Ğ»ÑŒ', 'Ğ“Ğ¾Ğ½Ñ‡Ğ°Ñ€', 'ĞšÑ€Ğ°Ğ²ĞµÑ†ÑŒ', 'Ğ¨Ğ²ĞµÑ†ÑŒ',\n",
    "            'Ğ–ÑƒĞº', 'ĞšĞ¾Ğ·Ğ»Ğ¾Ğ²', 'ĞœĞ¾Ñ€Ğ¾Ğ·', 'Ğ¢ĞµÑ€ĞµÑ‰ĞµĞ½ĞºĞ¾', 'Ğ Ğ¸Ğ±Ğ°Ğ»ĞºĞ¾'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'post_processing': {\n",
    "        'extract_person_regions': True,\n",
    "        'clustering_eps': 300\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ… Configuration optimized for local environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“„ Load Test Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your test image path here\n",
    "test_image_paths = [\n",
    "    \"/home/maria/ssd990/projects/tarkovsky/Ğ-2982_4_1001/804-03494422-l-m-a-n2982-4-1001-00002.jpg\",\n",
    "    \"../test_images/ukrainian_document.jpg\",\n",
    "    \"./sample_document.jpg\",\n",
    "    # Add your document paths here\n",
    "]\n",
    "\n",
    "test_image_path = None\n",
    "for path in test_image_paths:\n",
    "    if os.path.exists(path):\n",
    "        test_image_path = path\n",
    "        break\n",
    "\n",
    "if test_image_path:\n",
    "    # Load and display document information\n",
    "    image_size = os.path.getsize(test_image_path) / (1024 * 1024)\n",
    "    \n",
    "    with Image.open(test_image_path) as img:\n",
    "        width, height = img.size\n",
    "        \n",
    "        print(f\"ğŸ“„ Document: {os.path.basename(test_image_path)}\")\n",
    "        print(f\"ğŸ“Š Size: {image_size:.1f} MB\")\n",
    "        print(f\"ğŸ“ Dimensions: {width} x {height} pixels\")\n",
    "        print(f\"ğŸ“ Format: {img.format}\")\n",
    "        \n",
    "        # Display preview\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Document: {os.path.basename(test_image_path)}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\nelse:\n",
    "    print(\"âŒ No test document found!\")\n",
    "    print(\"Please update the test_image_paths list with your document path.\")\n",
    "    print(\"Supported formats: JPG, PNG, TIFF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ Stage 1: Document Segmentation & Basic ALTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not test_image_path:\n",
    "    print(\"âŒ Cannot proceed without a document. Please check the cell above.\")\n",
    "else:\n",
    "    print(\"ğŸš€ STAGE 1: Document Segmentation & Basic ALTO Creation\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Initialize pipeline\n",
    "    pipeline_config = OCRPipelineConfig.from_dict(config)\n",
    "    pipeline = UkrainianOCRPipeline(config=pipeline_config)\n",
    "    \n",
    "    print(f\"âœ… Pipeline ready (device: {pipeline.device})\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = Path(\"./ukrainian_ocr_output\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Load and process image\n",
    "    print(\"\\nğŸ” Kraken Segmentation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize components\n",
    "    pipeline._init_components()\n",
    "    \n",
    "    # Load image\n",
    "    image = cv2.imread(test_image_path)\n",
    "    \n",
    "    # Segment image\n",
    "    lines = pipeline.segmenter.segment_image(image)\n",
    "    seg_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"âœ… Segmentation complete: {seg_time:.2f}s\")\n",
    "    print(f\"ğŸ“Š Detected {len(lines)} text lines\")\n",
    "    \n",
    "    # Create basic ALTO XML\n",
    "    print(\"\\nğŸ“„ Creating basic ALTO XML...\")\n",
    "    basic_alto_xml = pipeline._create_alto_xml(Path(test_image_path), image, lines)\n",
    "    \n",
    "    basic_alto_path = output_dir / f\"{Path(test_image_path).stem}_basic_alto.xml\"\n",
    "    with open(basic_alto_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(basic_alto_xml)\n",
    "    \n",
    "    print(f\"âœ… Basic ALTO created: {basic_alto_path}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    print(\"\\nğŸ¨ Creating segmentation visualization...\")\n",
    "    vis_image = image.copy()\n",
    "    colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0)]\n",
    "    \n",
    "    for idx, line in enumerate(lines[:200]):  # Show first 200 lines\n",
    "        color = colors[idx % len(colors)]\n",
    "        polygon = line.get('polygon', [])\n",
    "        if polygon and len(polygon) >= 3:\n",
    "            pts = np.array(polygon, np.int32)\n",
    "            cv2.polylines(vis_image, [pts], True, color, 2)\n",
    "    \n",
    "    # Save and display visualization\n",
    "    vis_path = output_dir / f\"{Path(test_image_path).stem}_segmentation.png\"\n",
    "    cv2.imwrite(str(vis_path), vis_image)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Segmentation: {len(lines)} lines detected\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"âœ… Stage 1 complete - ready for text recognition\")\n",
    "    \n",
    "    # Store results for Stage 2\n",
    "    stage1_results = {\n",
    "        'image': image,\n",
    "        'lines': lines,\n",
    "        'segmentation_time': seg_time,\n",
    "        'basic_alto_path': basic_alto_path,\n",
    "        'output_dir': output_dir\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– Stage 2: Text Recognition, NER & Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'stage1_results' not in locals():\n",
    "    print(\"âŒ Please run Stage 1 first\")\n",
    "else:\n",
    "    print(\"ğŸš€ STAGE 2: Text Recognition, NER & Enhancement\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    image = stage1_results['image']\n",
    "    lines = stage1_results['lines']\n",
    "    output_dir = stage1_results['output_dir']\n",
    "    \n",
    "    print(f\"ğŸ“„ Processing {len(lines)} lines\")\n",
    "    \n",
    "    # Text Recognition with TrOCR\n",
    "    print(\"\\nğŸ¤– TrOCR Text Recognition...\")\n",
    "    if device == 'cpu':\n",
    "        print(\"â³ CPU processing - this will take several minutes\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    lines_with_text = pipeline.ocr_processor.process_lines(image, lines)\n",
    "    ocr_time = time.time() - start_time\n",
    "    \n",
    "    recognized_lines = [l for l in lines_with_text if l.get('text', '').strip()]\n",
    "    print(f\"âœ… OCR complete: {ocr_time:.2f}s\")\n",
    "    print(f\"ğŸ“Š Text in {len(recognized_lines)}/{len(lines)} lines\")\n",
    "    \n",
    "    # Show sample text\n",
    "    print(\"\\nğŸ“ Sample recognized text:\")\n",
    "    for i, line in enumerate(recognized_lines[:8]):\n",
    "        text = line.get('text', '')\n",
    "        conf = line.get('confidence', 0)\n",
    "        print(f\"  {i+1}. '{text}' ({conf:.2f})\")\n",
    "    \n",
    "    # Named Entity Recognition\n",
    "    print(\"\\nğŸ·ï¸ Named Entity Recognition...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ner_results = pipeline.ner_extractor.extract_entities_from_lines(lines_with_text)\n",
    "    ner_time = time.time() - start_time\n",
    "    \n",
    "    all_entities = ner_results.get('all_entities', [])\n",
    "    print(f\"âœ… NER complete: {ner_time:.2f}s\")\n",
    "    print(f\"ğŸ·ï¸ Found {len(all_entities)} entities\")\n",
    "    print(f\"ğŸ§  Backend: {ner_results.get('backend', 'unknown')}\")\n",
    "    \n",
    "    if all_entities:\n",
    "        # Group by type\n",
    "        entity_types = {}\n",
    "        for entity in all_entities:\n",
    "            label = entity.get('label', 'UNKNOWN')\n",
    "            entity_types[label] = entity_types.get(label, 0) + 1\n",
    "        \n",
    "        print(\"\\nEntity types:\")\n",
    "        for etype, count in entity_types.items():\n",
    "            print(f\"  {etype}: {count}\")\n",
    "        \n",
    "        print(\"\\nSample entities:\")\n",
    "        for entity in all_entities[:8]:\n",
    "            print(f\"  '{entity.get('text', '')}' -> {entity.get('label', '')}\")\n",
    "    \n",
    "    # Surname Matching\n",
    "    print(\"\\nğŸ‘¥ Surname Matching...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    surname_matches = pipeline.surname_matcher.find_in_lines(lines_with_text)\n",
    "    surname_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"âœ… Surname matching: {surname_time:.2f}s\")\n",
    "    print(f\"ğŸ‘¥ Found {len(surname_matches)} matches\")\n",
    "    \n",
    "    if surname_matches:\n",
    "        unique_surnames = set(m.matched_surname for m in surname_matches)\n",
    "        print(f\"ğŸ“Š Unique surnames: {len(unique_surnames)}\")\n",
    "        \n",
    "        print(\"\\nSample matches:\")\n",
    "        for match in surname_matches[:8]:\n",
    "            print(f\"  '{match.found_text}' -> '{match.matched_surname}' ({match.confidence:.2f})\")\n",
    "        \n",
    "        # Export matches\n",
    "        matches_file = output_dir / f\"{Path(test_image_path).stem}_surnames.json\"\n",
    "        pipeline.surname_matcher.export_matches(surname_matches, str(matches_file))\n",
    "        print(f\"ğŸ’¾ Surnames saved: {matches_file}\")\n",
    "    \n",
    "    # Create Enhanced ALTO\n",
    "    print(\"\\nâœ¨ Creating Enhanced ALTO...\")\n",
    "    \n",
    "    # Complete ALTO with text\n",
    "    complete_alto_xml = pipeline._create_alto_xml(Path(test_image_path), image, lines_with_text)\n",
    "    complete_alto_path = output_dir / f\"{Path(test_image_path).stem}_complete_alto.xml\"\n",
    "    \n",
    "    with open(complete_alto_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(complete_alto_xml)\n",
    "    \n",
    "    print(f\"âœ… Complete ALTO: {complete_alto_path}\")\n",
    "    \n",
    "    # Enhanced ALTO with NER (if entities found)\n",
    "    enhanced_alto_path = None\n",
    "    if all_entities:\n",
    "        # Map entities to lines\n",
    "        entities_by_line_id = {}\n",
    "        for idx, line in enumerate(lines_with_text):\n",
    "            line_id = f\"line_{idx}\"\n",
    "            line_text = line.get('text', '')\n",
    "            \n",
    "            line_entities = []\n",
    "            for entity in all_entities:\n",
    "                if entity.get('text', '') in line_text:\n",
    "                    line_entities.append(entity)\n",
    "            \n",
    "            if line_entities:\n",
    "                entities_by_line_id[line_id] = {'entities': line_entities}\n",
    "        \n",
    "        if entities_by_line_id:\n",
    "            enhanced_alto_path = output_dir / f\"{Path(test_image_path).stem}_enhanced_alto.xml\"\n",
    "            pipeline.alto_enhancer.enhance_alto_with_ner(\n",
    "                str(complete_alto_path), entities_by_line_id, str(enhanced_alto_path)\n",
    "            )\n",
    "            print(f\"âœ… Enhanced ALTO: {enhanced_alto_path}\")\n",
    "    \n",
    "    # Final Summary\n",
    "    total_time = stage1_results['segmentation_time'] + ocr_time + ner_time + surname_time\n",
    "    \n",
    "    print(\"\\nğŸ“Š PROCESSING COMPLETE\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"â±ï¸ Total time: {total_time:.2f}s\")\n",
    "    print(f\"ğŸ” Lines detected: {len(lines)}\")\n",
    "    print(f\"ğŸ“ Lines with text: {len(recognized_lines)}\")\n",
    "    print(f\"ğŸ·ï¸ Entities found: {len(all_entities)}\")\n",
    "    print(f\"ğŸ‘¥ Surname matches: {len(surname_matches)}\")\n",
    "    \n",
    "    # List output files\n",
    "    print(\"\\nğŸ“ Generated files:\")\n",
    "    for file_path in output_dir.glob(\"*\"):\n",
    "        size_kb = file_path.stat().st_size / 1024\n",
    "        print(f\"  ğŸ“„ {file_path.name} ({size_kb:.1f} KB)\")\n",
    "    \n",
    "    print(f\"\\nâœ… All files saved in: {output_dir}\")\n",
    "    print(\"ğŸ‰ Ukrainian OCR processing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Results Summary\n",
    "\n",
    "### Generated Files:\n",
    "- **Basic ALTO XML**: Segmentation with coordinates\n",
    "- **Complete ALTO XML**: Full transcription with confidence scores  \n",
    "- **Enhanced ALTO XML**: With NER semantic annotations (if entities found)\n",
    "- **Surname Matches JSON**: Genealogical findings with fuzzy matching\n",
    "- **Segmentation PNG**: Visual representation of detected lines\n",
    "\n",
    "### Next Steps:\n",
    "1. **Review ALTO files** in XML editor or eScriptorium\n",
    "2. **Analyze surname matches** for genealogical research\n",
    "3. **Process additional documents** with the same configuration\n",
    "4. **Customize surname lists** for specific family names\n",
    "5. **Adjust confidence thresholds** for better precision/recall balance\n",
    "\n",
    "### Performance Tips:\n",
    "- Use **GPU** for faster processing (especially OCR step)\n",
    "- Increase **batch_size** for better GPU utilization\n",
    "- Try different **NER backends** (transformers/spacy/rule-based)\n",
    "- Adjust **surname matching threshold** (0.7-0.9 range)\n",
    "\n",
    "---\n",
    "**ğŸ‡ºğŸ‡¦ Ukrainian OCR Pipeline** - Optimized for local development environments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}